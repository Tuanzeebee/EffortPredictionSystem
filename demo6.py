# -*- coding: utf-8 -*-
"""
app.py: ·ª®ng d·ª•ng Web Streamlit ƒë·ªÉ d·ª± ƒëo√°n Effort
(Bao g·ªìm M√¥ h√¨nh ML, COCOMO II Basic, FP, UCP, chuy·ªÉn ƒë·ªïi LOC/UCP/FP, Development Time, Team Size v√† So s√°nh).
"""

import streamlit as st
import pandas as pd
import numpy as np
import joblib
import os
from collections import OrderedDict
import math
import traceback
import uuid  # ƒê·ªÉ t·∫°o UUID cho artifact_id n·∫øu c·∫ßn

# Import c√°c l·ªõp c·∫ßn thi·∫øt
try:
    from sklearn.compose import ColumnTransformer
    from sklearn.pipeline import Pipeline
    from sklearn.impute import SimpleImputer
    from sklearn.preprocessing import RobustScaler, OneHotEncoder
    from sklearn.linear_model import LinearRegression
    from sklearn.tree import DecisionTreeRegressor
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.neural_network import MLPRegressor
    import xgboost as xgb
except ImportError as e:
    st.error(f"L·ªói Import th∆∞ vi·ªán: {e}. H√£y ƒë·∫£m b·∫£o c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t.")
    st.stop()

# --- C·∫•u h√¨nh Trang ---
st.set_page_config(page_title="So s√°nh ∆Ø·ªõc t√≠nh Effort Ph·∫ßn m·ªÅm", layout="wide")
st.title("·ª®ng d·ª•ng So s√°nh ∆Ø·ªõc t√≠nh Effort Ph·∫ßn m·ªÅm üìä")
st.write("""
Nh·∫≠p th√¥ng tin d·ª± √°n ƒë·ªÉ nh·∫≠n ∆∞·ªõc t√≠nh effort (person-hours), development time (th√°ng), team size,
v√† chuy·ªÉn ƒë·ªïi gi·ªØa LOC, UCP, FP t·ª´ nhi·ªÅu m√¥ h√¨nh Machine Learning v√† ph∆∞∆°ng ph√°p truy·ªÅn th·ªëng.
""")

# ƒê·ªãnh nghƒ©a ƒë∆∞·ªùng d·∫´n
OUTPUT_DIR = "."
PREPROCESSOR_PATH = os.path.join(OUTPUT_DIR, "preprocessor.joblib")
FEATURES_PATH = os.path.join(OUTPUT_DIR, "feature_names.joblib")
MODEL_PATHS = OrderedDict([
    ('Linear Regression', os.path.join(OUTPUT_DIR, "linear_regression_model.joblib")),
    ('Decision Tree', os.path.join(OUTPUT_DIR, "decision_tree_model.joblib")),
    ('Random Forest', os.path.join(OUTPUT_DIR, "random_forest_model.joblib")),
    ('XGBoost', os.path.join(OUTPUT_DIR, "xgboost_model.joblib")),
    ('MLP Regressor', os.path.join(OUTPUT_DIR, "mlp_regressor_model.joblib"))
])

@st.cache_resource
def load_all_artifacts(preprocessor_path, features_path, model_paths_dict):
    """
    T·∫£i preprocessor, feature names, c√°c m√¥ h√¨nh ML, v√† tr√≠ch xu·∫•t c√°c danh m·ª•c.
    """
    loaded_models = OrderedDict()
    preprocessor = None
    feature_names = None
    categorical_features_options = {}
    original_cols_order = []
    all_loaded_successfully = True

    # --- T·∫£i Preprocessor ---
    if not os.path.exists(preprocessor_path):
        st.error(f"L·ªñI: Kh√¥ng t√¨m th·∫•y file preprocessor t·∫°i '{preprocessor_path}'")
        return None, None, None, None, None
    try:
        preprocessor = joblib.load(preprocessor_path)
        print("T·∫£i preprocessor th√†nh c√¥ng.")
        try:
            num_transformer_tuple = next(t for t in preprocessor.transformers_ if t[0] == 'num')
            cat_transformer_tuple = next(t for t in preprocessor.transformers_ if t[0] == 'cat')
            original_num_features = list(num_transformer_tuple[2])
            original_cat_features = list(cat_transformer_tuple[2])
            original_cols_order = original_num_features + original_cat_features
            print("Th·ª© t·ª± c·ªôt g·ªëc mong ƒë·ª£i:", original_cols_order)

            cat_pipeline = preprocessor.named_transformers_['cat']
            onehot_encoder = cat_pipeline.named_steps['onehot']
            if hasattr(onehot_encoder, 'categories_'):
                if len(onehot_encoder.categories_) == len(original_cat_features):
                    for i, feature_name in enumerate(original_cat_features):
                        categories = onehot_encoder.categories_[i]
                        categorical_features_options[feature_name] = categories.tolist()
                    print("Tr√≠ch xu·∫•t danh m·ª•c t·ª´ OneHotEncoder th√†nh c√¥ng.")
                else:
                    st.error(f"L·ªói: S·ªë l∆∞·ª£ng danh m·ª•c kh√¥ng kh·ªõp s·ªë c·ªôt ph√¢n lo·∫°i.")
                    all_loaded_successfully = False
            else:
                st.error("L·ªói: Kh√¥ng t√¨m th·∫•y thu·ªôc t√≠nh 'categories_' trong OneHotEncoder.")
                all_loaded_successfully = False
        except Exception as e_extract:
            st.error(f"L·ªói khi tr√≠ch xu·∫•t th√¥ng tin t·ª´ preprocessor: {e_extract}")
            all_loaded_successfully = False
    except Exception as e_load_prep:
        st.error(f"L·ªói nghi√™m tr·ªçng khi t·∫£i preprocessor: {e_load_prep}")
        return None, None, None, None, None

    # --- T·∫£i Feature Names ---
    if not os.path.exists(features_path):
        st.error(f"L·ªñI: Kh√¥ng t√¨m th·∫•y file t√™n ƒë·∫∑c tr∆∞ng t·∫°i '{features_path}'")
        all_loaded_successfully = False
    else:
        try:
            feature_names = joblib.load(features_path)
            print("T·∫£i feature names th√†nh c√¥ng.")
            if isinstance(feature_names, np.ndarray):
                feature_names = feature_names.tolist()
            if not isinstance(feature_names, list):
                st.warning(f"ƒê·ªãnh d·∫°ng feature_names kh√¥ng ph·∫£i list.")
                try:
                    feature_names = list(feature_names)
                except TypeError:
                    st.error("Kh√¥ng th·ªÉ chuy·ªÉn ƒë·ªïi feature_names th√†nh list.")
                    all_loaded_successfully = False
        except Exception as e_load_feat:
            st.error(f"L·ªói khi t·∫£i feature names: {e_load_feat}")
            all_loaded_successfully = False

    # --- T·∫£i c√°c M√¥ h√¨nh ML ---
    models_actually_loaded = 0
    for name, path in model_paths_dict.items():
        if not os.path.exists(path):
            st.warning(f"C·∫£nh b√°o: Kh√¥ng t√¨m th·∫•y file m√¥ h√¨nh '{name}' t·∫°i '{path}'. B·ªè qua.")
            continue
        try:
            model = joblib.load(path)
            loaded_models[name] = model
            models_actually_loaded += 1
            print(f"T·∫£i m√¥ h√¨nh ML {name} th√†nh c√¥ng.")
        except Exception as e_load_model:
            st.warning(f"L·ªói khi t·∫£i m√¥ h√¨nh {name}: {e_load_model}. B·ªè qua.")

    if models_actually_loaded == 0:
        st.error("L·ªñI: Kh√¥ng t·∫£i ƒë∆∞·ª£c b·∫•t k·ª≥ m√¥ h√¨nh Machine Learning n√†o.")
        all_loaded_successfully = False

    return preprocessor, feature_names, loaded_models, original_cols_order, categorical_features_options

# --- H√†m chuy·ªÉn ƒë·ªïi gi·ªØa LOC, FP, UCP ---
def loc_to_fp(loc, loc_per_fp):
    """Chuy·ªÉn ƒë·ªïi t·ª´ LOC sang FP."""
    if loc <= 0 or loc_per_fp <= 0:
        return "L·ªói (LOC ho·∫∑c h·ªá s·ªë <= 0)"
    try:
        fp = loc / loc_per_fp
        return max(0.0, round(fp, 2))
    except Exception as e:
        return f"L·ªói t√≠nh to√°n: {e}"

def fp_to_loc(fp, loc_per_fp):
    """Chuy·ªÉn ƒë·ªïi t·ª´ FP sang LOC."""
    if fp <= 0 or loc_per_fp <= 0:
        return "L·ªói (FP ho·∫∑c h·ªá s·ªë <= 0)"
    try:
        loc = fp * loc_per_fp
        return max(0.0, round(loc, 2))
    except Exception as e:
        return f"L·ªói t√≠nh to√°n: {e}"

def fp_to_ucp(fp, fp_per_ucp):
    """Chuy·ªÉn ƒë·ªïi t·ª´ FP sang UCP."""
    if fp <= 0 or fp_per_ucp <= 0:
        return "L·ªói (FP ho·∫∑c h·ªá s·ªë <= 0)"
    try:
        ucp = fp / fp_per_ucp
        return max(0.0, round(ucp, 2))
    except Exception as e:
        return f"L·ªói t√≠nh to√°n: {e}"

def ucp_to_fp(ucp, fp_per_ucp):
    """Chuy·ªÉn ƒë·ªïi t·ª´ UCP sang FP."""
    if ucp <= 0 or fp_per_ucp <= 0:
        return "L·ªói (UCP ho·∫∑c h·ªá s·ªë <= 0)"
    try:
        fp = ucp * fp_per_ucp
        return max(0.0, round(fp, 2))
    except Exception as e:
        return f"L·ªói t√≠nh to√°n: {e}"

# --- H√†m t√≠nh to√°n cho m√¥ h√¨nh truy·ªÅn th·ªëng ---
def calculate_cocomo_basic(loc, mode, eaf, hrs_per_month):
    """T√≠nh to√°n effort theo COCOMO II Basic (quy ƒë·ªïi ra person-hours)."""
    if loc <= 0:
        return "L·ªói (LOC <= 0)"
    if hrs_per_month <= 0:
        return "L·ªói (Gi·ªù/Th√°ng <= 0)"
    kloc = loc / 1000.0
    params = {
        "Organic": {"a": 2.4, "b": 1.05},
        "Semi-detached": {"a": 3.0, "b": 1.12},
        "Embedded": {"a": 3.6, "b": 1.20}
    }
    if mode not in params:
        return "L·ªói (Ch·∫ø ƒë·ªô kh√¥ng h·ª£p l·ªá)"
    a = params[mode]["a"]
    b = params[mode]["b"]
    try:
        person_months = a * (kloc ** b) * eaf
        person_hours = person_months * hrs_per_month
        return max(0.0, round(person_hours, 2))
    except Exception as e:
        return f"L·ªói t√≠nh to√°n: {e}"

def calculate_fp_effort(fp, hrs_per_fp):
    """T√≠nh to√°n effort d·ª±a tr√™n Function Points."""
    if fp <= 0:
        return "L·ªói (FP <= 0)"
    if hrs_per_fp <= 0:
        return "L·ªói (Gi·ªù/FP <= 0)"
    try:
        person_hours = fp * hrs_per_fp
        return max(0.0, round(person_hours, 2))
    except Exception as e:
        return f"L·ªói t√≠nh to√°n: {e}"

def calculate_ucp_effort(ucp, hrs_per_ucp):
    """T√≠nh to√°n effort d·ª±a tr√™n Use Case Points."""
    if ucp <= 0:
        return "L·ªói (UCP <= 0)"
    if hrs_per_ucp <= 0:
        return "L·ªói (Gi·ªù/UCP <= 0)"
    try:
        person_hours = ucp * hrs_per_ucp
        return max(0.0, round(person_hours, 2))
    except Exception as e:
        return f"L·ªói t√≠nh to√°n: {e}"

def calculate_development_time(effort, team_size, hrs_per_month):
    """T√≠nh development time (th√°ng) t·ª´ effort."""
    if effort <= 0 or team_size <= 0 or hrs_per_month <= 0:
        return "L·ªói (Effort, Team Size ho·∫∑c Gi·ªù/Th√°ng <= 0)"
    try:
        time_months = effort / (team_size * hrs_per_month)
        return max(0.0, round(time_months, 2))
    except Exception as e:
        return f"L·ªói t√≠nh to√°n: {e}"

def calculate_team_size(effort, dev_time, hrs_per_month):
    """T√≠nh team size t·ª´ effort v√† development time."""
    if effort <= 0 or dev_time <= 0 or hrs_per_month <= 0:
        return "L·ªói (Effort, Dev Time ho·∫∑c Gi·ªù/Th√°ng <= 0)"
    try:
        team_size = effort / (dev_time * hrs_per_month)
        return max(0.0, round(team_size, 2))
    except Exception as e:
        return f"L·ªói t√≠nh to√°n: {e}"

# --- T·∫£i Artifacts ---
preprocessor, feature_names_out, ml_models, original_cols_order, categorical_features_options = load_all_artifacts(
    PREPROCESSOR_PATH, FEATURES_PATH, MODEL_PATHS
)

# --- T·∫°o Giao di·ªán Nh·∫≠p li·ªáu ---
st.sidebar.header("Nh·∫≠p Th√¥ng tin D·ª± √°n")
input_values = {}

# --- Widget nh·∫≠p li·ªáu cho ML v√† M√¥ h√¨nh truy·ªÅn th·ªëng ---
st.sidebar.subheader("ƒê·∫∑c tr∆∞ng C∆° b·∫£n (S·ª≠ d·ª•ng b·ªüi nhi·ªÅu m√¥ h√¨nh)")
col1, col2 = st.sidebar.columns(2)
with col1:
    input_values['LOC'] = st.number_input("Lines of Code (LOC)", min_value=0, value=10000, step=100, key="loc_input")
    input_values['FP'] = st.number_input("Function Points (FP)", min_value=0, value=100, step=10, key="fp_input")
with col2:
    input_values['UCP'] = st.number_input("Use Case Points (UCP)", min_value=0.0, value=100.0, step=10.0, format="%.2f", key="ucp_input")

# --- Widget nh·∫≠p li·ªáu ch·ªâ cho ML ---
if preprocessor and original_cols_order and categorical_features_options:
    st.sidebar.subheader("ƒê·∫∑c tr∆∞ng B·ªï sung (Ch·ªß y·∫øu cho ML)")
    col_ml1, col_ml2 = st.sidebar.columns(2)
    with col_ml1:
        if 'Development Time (months)' in original_cols_order:
            input_values['Development Time (months)'] = st.number_input("Development Time (months)", min_value=1, value=6, step=1)
    with col_ml2:
        if 'Team Size' in original_cols_order:
            input_values['Team Size'] = st.number_input("Team Size", min_value=1, value=5, step=1)

    st.sidebar.subheader("Th√¥ng tin Ph√¢n lo·∫°i (Ch·ªß y·∫øu cho ML)")
    col_cat1, col_cat2 = st.sidebar.columns(2)
    categorical_cols_with_options = list(categorical_features_options.keys())
    with col_cat1:
        for i, col_name in enumerate(categorical_cols_with_options[:len(categorical_cols_with_options)//2]):
            if col_name in original_cols_order:
                options = categorical_features_options[col_name]
                input_values[col_name] = st.selectbox(f"{col_name}", options=options, index=0, key=f"sb_{col_name}_1")
    with col_cat2:
        for i, col_name in enumerate(categorical_cols_with_options[len(categorical_cols_with_options)//2:]):
            if col_name in original_cols_order:
                options = categorical_features_options[col_name]
                input_values[col_name] = st.selectbox(f"{col_name}", options=options, index=0, key=f"sb_{col_name}_2")
else:
    st.sidebar.warning("Kh√¥ng th·ªÉ t·∫£i preprocessor ho·∫∑c th√¥ng tin c·ªôt ML. Ph·∫ßn nh·∫≠p li·ªáu cho ML b·ªã v√¥ hi·ªáu h√≥a.")

# --- Widget nh·∫≠p li·ªáu cho M√¥ h√¨nh Truy·ªÅn th·ªëng ---
st.sidebar.subheader("Tham s·ªë cho M√¥ h√¨nh Truy·ªÅn th·ªëng")

# Chuy·ªÉn ƒë·ªïi LOC, FP, UCP
st.sidebar.markdown("**Chuy·ªÉn ƒë·ªïi LOC/FP/UCP**")
loc_per_fp = st.sidebar.number_input("LOC per FP (Java: ~53)", min_value=0.1, value=53.0, step=1.0, format="%.1f", key="loc_per_fp")
fp_per_ucp = st.sidebar.number_input("FP per UCP (~5-15)", min_value=0.1, value=10.0, step=1.0, format="%.1f", key="fp_per_ucp")

# COCOMO II Basic
st.sidebar.markdown("**COCOMO II (Basic)**")
cocomo_mode = st.sidebar.selectbox("Ch·∫ø ƒë·ªô D·ª± √°n", ["Organic", "Semi-detached", "Embedded"], key="cocomo_mode")
eaf = st.sidebar.number_input("H·ªá s·ªë ƒêi·ªÅu ch·ªânh N·ªó l·ª±c (EAF)", min_value=0.1, value=1.0, step=0.1, format="%.2f", key="eaf")
hours_per_month = st.sidebar.number_input("S·ªë gi·ªù l√†m vi·ªác/th√°ng", min_value=1, value=152, step=8, key="hrs_month")

# Function Points
st.sidebar.markdown("**Function Points (FP)**")
hours_per_fp = st.sidebar.number_input("S·ªë gi·ªù/Function Point", min_value=0.1, value=10.0, step=0.5, format="%.1f", key="hrs_fp")

# Use Case Points
st.sidebar.markdown("**Use Case Points (UCP)**")
hours_per_ucp = st.sidebar.number_input("S·ªë gi·ªù/Use Case Point", min_value=0.1, value=20.0, step=1.0, format="%.1f", key="hrs_ucp")

# Development Time v√† Team Size
st.sidebar.markdown("**Development Time & Team Size**")
team_size_input = st.sidebar.number_input("Team Size (d√πng ƒë·ªÉ t√≠nh Dev Time)", min_value=1, value=5, step=1, key="team_size_input")
dev_time_input = st.sidebar.number_input("Development Time (th√°ng, d√πng ƒë·ªÉ t√≠nh Team Size)", min_value=0.1, value=6.0, step=0.1, format="%.1f", key="dev_time_input")

# --- N√∫t D·ª± ƒëo√°n/T√≠nh to√°n ---
calculate_button = st.sidebar.button("üìä ∆Ø·ªõc t√≠nh & So s√°nh", use_container_width=True, type="primary")

# --- X·ª≠ l√Ω v√† Hi·ªÉn th·ªã K·∫øt qu·∫£ ---
if calculate_button:
    st.divider()
    st.subheader("üìä K·∫øt qu·∫£ ∆Ø·ªõc t√≠nh T·ªïng h·ª£p")
    all_results = OrderedDict()
    error_messages = {}

    # --- 1. Chuy·ªÉn ƒë·ªïi LOC, FP, UCP ---
    st.markdown("#### 1. K·∫øt qu·∫£ Chuy·ªÉn ƒë·ªïi LOC/FP/UCP")
    loc_val = input_values.get('LOC', 0)
    fp_val = input_values.get('FP', 0)
    ucp_val = input_values.get('UCP', 0)

    conversions = {
        "FP t·ª´ LOC": loc_to_fp(loc_val, loc_per_fp),
        "LOC t·ª´ FP": fp_to_loc(fp_val, loc_per_fp),
        "UCP t·ª´ FP": fp_to_ucp(fp_val, fp_per_ucp),
        "FP t·ª´ UCP": ucp_to_fp(ucp_val, fp_per_ucp)
    }
    conversion_df = pd.DataFrame(list(conversions.items()), columns=['Chuy·ªÉn ƒë·ªïi', 'K·∫øt qu·∫£'])
    st.dataframe(conversion_df, use_container_width=True, hide_index=True)
    st.caption(f"Tham s·ªë: LOC per FP = {loc_per_fp}, FP per UCP = {fp_per_ucp}")

    # --- 2. D·ª± ƒëo√°n t·ª´ M√¥ h√¨nh Machine Learning ---
    if preprocessor and feature_names_out and ml_models and original_cols_order and categorical_features_options:
        st.markdown("#### 2. D·ª± ƒëo√°n t·ª´ M√¥ h√¨nh Machine Learning")
        try:
            ordered_input_data_ml = {}
            missing_inputs_ml = []
            for col in original_cols_order:
                if col in input_values:
                    ordered_input_data_ml[col] = input_values[col]
                else:
                    missing_inputs_ml.append(col)
                    ordered_input_data_ml[col] = np.nan
            if missing_inputs_ml:
                st.warning(f"ML Input: Thi·∫øu gi√° tr·ªã cho: {', '.join(missing_inputs_ml)}.")
            input_df_ml = pd.DataFrame([ordered_input_data_ml], columns=original_cols_order)
            input_processed_np = preprocessor.transform(input_df_ml)
            if isinstance(feature_names_out, list) and len(feature_names_out) == input_processed_np.shape[1]:
                input_processed_df = pd.DataFrame(input_processed_np, columns=feature_names_out)
                for model_name, loaded_model in ml_models.items():
                    try:
                        pred = loaded_model.predict(input_processed_df)
                        prediction_value = float(pred[0]) if pred.size > 0 else 0.0
                        all_results[f"ML: {model_name}"] = {
                            'Effort (person-hours)': max(0.0, round(prediction_value, 2)),
                            'Dev Time (months)': calculate_development_time(prediction_value, team_size_input, hours_per_month),
                            'Team Size': calculate_team_size(prediction_value, dev_time_input, hours_per_month)
                        }
                    except Exception as model_pred_e:
                        error_messages[model_name] = str(model_pred_e)
                        all_results[f"ML: {model_name}"] = {'Effort (person-hours)': "L·ªói", 'Dev Time (months)': "L·ªói", 'Team Size': "L·ªói"}
            else:
                st.error(f"L·ªói ML: S·ªë l∆∞·ª£ng t√™n ƒë·∫∑c tr∆∞ng kh√¥ng kh·ªõp.")
                for model_name in ml_models.keys():
                    all_results[f"ML: {model_name}"] = {'Effort (person-hours)': "L·ªói (Config)", 'Dev Time (months)': "L·ªói", 'Team Size': "L·ªói"}
        except Exception as e_ml_process:
            st.error(f"L·ªói nghi√™m tr·ªçng trong ML: {e_ml_process}")
            for model_name in ml_models.keys():
                all_results[f"ML: {model_name}"] = {'Effort (person-hours)': "L·ªói (Process)", 'Dev Time (months)': "L·ªói", 'Team Size': "L·ªói"}
            print(traceback.format_exc())
    else:
        st.info("Ph·∫ßn d·ª± ƒëo√°n ML kh√¥ng th·ª±c hi·ªán do thi·∫øu th√†nh ph·∫ßn c·∫ßn thi·∫øt.")

    # --- 3. T√≠nh to√°n t·ª´ M√¥ h√¨nh Truy·ªÅn th·ªëng ---
    st.markdown("#### 3. T√≠nh to√°n t·ª´ M√¥ h√¨nh Truy·ªÅn th·ªëng")
    traditional_captions = []

    # COCOMO II Basic
    cocomo_effort = calculate_cocomo_basic(loc_val, cocomo_mode, eaf, hours_per_month)
    cocomo_dev_time = calculate_development_time(cocomo_effort, team_size_input, hours_per_month) if isinstance(cocomo_effort, (int, float)) else "L·ªói"
    cocomo_team_size = calculate_team_size(cocomo_effort, dev_time_input, hours_per_month) if isinstance(cocomo_effort, (int, float)) else "L·ªói"
    all_results['COCOMO II (Basic)'] = {
        'Effort (person-hours)': cocomo_effort,
        'Dev Time (months)': cocomo_dev_time,
        'Team Size': cocomo_team_size
    }
    traditional_captions.append(f"* **COCOMO II (Basic):** Mode={cocomo_mode}, LOC={loc_val}, EAF={eaf}, Hours/Month={hours_per_month}")

    # Function Points
    fp_effort = calculate_fp_effort(fp_val, hours_per_fp)
    fp_dev_time = calculate_development_time(fp_effort, team_size_input, hours_per_month) if isinstance(fp_effort, (int, float)) else "L·ªói"
    fp_team_size = calculate_team_size(fp_effort, dev_time_input, hours_per_month) if isinstance(fp_effort, (int, float)) else "L·ªói"
    all_results['Function Points'] = {
        'Effort (person-hours)': fp_effort,
        'Dev Time (months)': fp_dev_time,
        'Team Size': fp_team_size
    }
    traditional_captions.append(f"* **Function Points:** FP={fp_val}, Hours/FP={hours_per_fp}")

    # Use Case Points
    ucp_effort = calculate_ucp_effort(ucp_val, hours_per_ucp)
    ucp_dev_time = calculate_development_time(ucp_effort, team_size_input, hours_per_month) if isinstance(ucp_effort, (int, float)) else "L·ªói"
    ucp_team_size = calculate_team_size(ucp_effort, dev_time_input, hours_per_month) if isinstance(ucp_effort, (int, float)) else "L·ªói"
    all_results['Use Case Points'] = {
        'Effort (person-hours)': ucp_effort,
        'Dev Time (months)': ucp_dev_time,
        'Team Size': ucp_team_size
    }
    traditional_captions.append(f"* **Use Case Points:** UCP={ucp_val}, Hours/UCP={hours_per_ucp}")

    st.markdown("**Tham s·ªë s·ª≠ d·ª•ng:**")
    for caption in traditional_captions:
        st.markdown(caption)
    st.caption("L∆∞u √Ω: K·∫øt qu·∫£ 'L·ªói' xu·∫•t hi·ªán n·∫øu ƒë·∫ßu v√†o kh√¥ng h·ª£p l·ªá.")

    # --- 4. Hi·ªÉn th·ªã B·∫£ng v√† Bi·ªÉu ƒë·ªì So s√°nh ---
    st.markdown("#### 4. B·∫£ng v√† Bi·ªÉu ƒë·ªì So s√°nh")
    if all_results:
        result_list = []
        for model_name, metrics in all_results.items():
            result_list.append({
                'M√¥ H√¨nh ∆Ø·ªõc T√≠nh': model_name,
                'Effort (person-hours)': metrics['Effort (person-hours)'],
                'Dev Time (months)': metrics['Dev Time (months)'],
                'Team Size': metrics['Team Size']
            })
        result_df = pd.DataFrame(result_list)

        def format_display(x):
            if isinstance(x, (int, float)):
                return f"{x:,.2f}"
            return str(x)
        st.write("B·∫£ng so s√°nh k·∫øt qu·∫£:")
        st.dataframe(
            result_df.style.format({
                'Effort (person-hours)': format_display,
                'Dev Time (months)': format_display,
                'Team Size': format_display
            }),
            use_container_width=True,
            hide_index=True
        )

        st.write("Bi·ªÉu ƒë·ªì so s√°nh Effort:")
        try:
            chart_df = result_df.copy()
            chart_df['Effort (person-hours)'] = pd.to_numeric(chart_df['Effort (person-hours)'].astype(str).str.replace(',', '', regex=False), errors='coerce')
            chart_df.dropna(subset=['Effort (person-hours)'], inplace=True)
            if not chart_df.empty:
                chart_data = chart_df.set_index('M√¥ H√¨nh ∆Ø·ªõc T√≠nh')['Effort (person-hours)']
                st.bar_chart(chart_data)
            else:
                st.info("Kh√¥ng c√≥ d·ª± ƒëo√°n/t√≠nh to√°n h·ª£p l·ªá ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì Effort.")
        except Exception as chart_e:
            st.warning(f"Kh√¥ng th·ªÉ v·∫Ω bi·ªÉu ƒë·ªì Effort: {chart_e}")
            print(traceback.format_exc())

        st.write("Bi·ªÉu ƒë·ªì so s√°nh Development Time:")
        try:
            chart_df = result_df.copy()
            chart_df['Dev Time (months)'] = pd.to_numeric(chart_df['Dev Time (months)'].astype(str).str.replace(',', '', regex=False), errors='coerce')
            chart_df.dropna(subset=['Dev Time (months)'], inplace=True)
            if not chart_df.empty:
                chart_data = chart_df.set_index('M√¥ H√¨nh ∆Ø·ªõc T√≠nh')['Dev Time (months)']
                st.bar_chart(chart_data)
            else:
                st.info("Kh√¥ng c√≥ d·ª± ƒëo√°n/t√≠nh to√°n h·ª£p l·ªá ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì Dev Time.")
        except Exception as chart_e:
            st.warning(f"Kh√¥ng th·ªÉ v·∫Ω bi·ªÉu ƒë·ªì Dev ^^Time: {chart_e}")
            print(traceback.format_exc())

        st.write("Bi·ªÉu ƒë·ªì so s√°nh Team Size:")
        try:
            chart_df = result_df.copy()
            chart_df['Team Size'] = pd.to_numeric(chart_df['Team Size'].astype(str).str.replace(',', '', regex=False), errors='coerce')
            chart_df.dropna(subset=['Team Size'], inplace=True)
            if not chart_df.empty:
                chart_data = chart_df.set_index('M√¥ H√¨nh ∆Ø·ªõc T√≠nh')['Team Size']
                st.bar_chart(chart_data)
            else:
                st.info("Kh√¥ng c√≥ d·ª± ƒëo√°n/t√≠nh to√°n h·ª£p l·ªá ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì Team Size.")
        except Exception as chart_e:
            st.warning(f"Kh√¥ng th·ªÉ v·∫Ω bi·ªÉu ƒë·ªì Team Size: {chart_e}")
            print(traceback.format_exc())

    else:
        st.warning("Kh√¥ng c√≥ k·∫øt qu·∫£ n√†o ƒë·ªÉ hi·ªÉn th·ªã.")

    if error_messages:
        st.subheader("‚ö†Ô∏è Chi ti·∫øt l·ªói d·ª± ƒëo√°n ML:")
        for model_name, msg in error_messages.items():
            st.caption(f"**{model_name}:** {msg}")

    st.info("""
    **L∆∞u √Ω quan tr·ªçng:**
    * K·∫øt qu·∫£ ch·ªâ l√† **∆∞·ªõc t√≠nh**. Effort, th·ªùi gian v√† ƒë·ªôi ng≈© th·ª±c t·∫ø c√≥ th·ªÉ kh√°c bi·ªát.
    * ƒê·ªô ch√≠nh x√°c c·ªßa ML ph·ª• thu·ªôc v√†o d·ªØ li·ªáu hu·∫•n luy·ªán.
    * ƒê·ªô ch√≠nh x√°c c·ªßa m√¥ h√¨nh truy·ªÅn th·ªëng ph·ª• thu·ªôc v√†o tham s·ªë (EAF, nƒÉng su·∫•t FP/UCP, h·ªá s·ªë chuy·ªÉn ƒë·ªïi).
    * S·ª≠ d·ª•ng k·∫øt qu·∫£ nh∆∞ tham kh·∫£o v√† k·∫øt h·ª£p v·ªõi kinh nghi·ªám th·ª±c t·∫ø.
    """)

# --- X·ª≠ l√Ω tr∆∞·ªùng h·ª£p kh√¥ng t·∫£i ƒë∆∞·ª£c artifacts ---
elif not ml_models and not preprocessor:
    st.error("Kh√¥ng th·ªÉ t·∫£i c√°c th√†nh ph·∫ßn c·∫ßn thi·∫øt cho d·ª± ƒëo√°n ML.")
    st.info("B·∫°n v·∫´n c√≥ th·ªÉ s·ª≠ d·ª•ng c√°c t√≠nh to√°n truy·ªÅn th·ªëng n·∫øu nh·∫≠p ƒë·ªß th√¥ng tin.")
elif not ml_models:
    st.warning("Kh√¥ng t·∫£i ƒë∆∞·ª£c m√¥ h√¨nh ML. Ch·ªâ s·ª≠ d·ª•ng t√≠nh to√°n truy·ªÅn th·ªëng.")
    st.info(f"Ki·ªÉm tra c√°c file .joblib trong th∆∞ m·ª•c '{OUTPUT_DIR}'.")
elif not preprocessor or not feature_names_out or not original_cols_order or not categorical_features_options:
    st.error("Kh√¥ng th·ªÉ t·∫£i preprocessor ho·∫∑c th√¥ng tin ƒë·∫∑c tr∆∞ng cho ML.")
    st.info("Ph·∫ßn d·ª± ƒëo√°n ML kh√¥ng ho·∫°t ƒë·ªông. V·∫´n c√≥ th·ªÉ s·ª≠ d·ª•ng t√≠nh to√°n truy·ªÅn th·ªëng.")
    st.info(f"Ki·ªÉm tra c√°c file '{PREPROCESSOR_PATH}' v√† '{FEATURES_PATH}'.")

# --- Ch√¢n trang ---
st.markdown("---")
st.caption("·ª®ng d·ª•ng demo x√¢y d·ª±ng v·ªõi Streamlit, Scikit-learn, XGBoost v√† c√°c m√¥ h√¨nh truy·ªÅn th·ªëng.")