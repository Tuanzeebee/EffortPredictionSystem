# -*- coding: utf-8 -*-
"""
app.py: ·ª®ng d·ª•ng Web Streamlit ƒë·ªÉ d·ª± ƒëo√°n Effort
(Bao g·ªìm M√¥ h√¨nh ML, COCOMO II Basic, FP, UCP v√† So s√°nh).
Phi√™n b·∫£n n√¢ng c·∫•p: Quy ƒë·ªïi LOC, FP, UCP v√† t√≠nh to√°n TDEV, Team Size.
"""

import streamlit as st
import pandas as pd
import numpy as np
import joblib
import os
from collections import OrderedDict
import math  # C·∫ßn cho COCOMO
import traceback  # Th√™m ƒë·ªÉ in l·ªói chi ti·∫øt

# Import c√°c l·ªõp c·∫ßn thi·∫øt
try:
    from sklearn.compose import ColumnTransformer
    from sklearn.pipeline import Pipeline
    from sklearn.impute import SimpleImputer
    from sklearn.preprocessing import RobustScaler, OneHotEncoder
    from sklearn.linear_model import LinearRegression
    from sklearn.tree import DecisionTreeRegressor
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.neural_network import MLPRegressor
    import xgboost as xgb
except ImportError as e:
    st.error(f"L·ªói Import th∆∞ vi·ªán: {e}. H√£y ƒë·∫£m b·∫£o c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t.")
    st.stop()

# --- C·∫•u h√¨nh Trang ---
st.set_page_config(page_title="So s√°nh ∆Ø·ªõc t√≠nh Effort Ph·∫ßn m·ªÅm", layout="wide")

st.title("·ª®ng d·ª•ng So s√°nh ∆Ø·ªõc t√≠nh Effort Ph·∫ßn m·ªÅm üìä")
st.write("""
Nh·∫≠p th√¥ng tin d·ª± √°n ƒë·ªÉ nh·∫≠n ∆∞·ªõc t√≠nh effort (person-hours), th·ªùi gian ph√°t tri·ªÉn, v√† k√≠ch th∆∞·ªõc ƒë·ªôi ng≈©
t·ª´ nhi·ªÅu m√¥ h√¨nh Machine Learning v√† c√°c ph∆∞∆°ng ph√°p truy·ªÅn th·ªëng.
""")

# --- ƒê·ªãnh nghƒ©a ƒê∆∞·ªùng d·∫´n v√† H·∫±ng s·ªë ---
OUTPUT_DIR = "."
PREPROCESSOR_PATH = os.path.join(OUTPUT_DIR, "preprocessor.joblib")
FEATURES_PATH = os.path.join(OUTPUT_DIR, "feature_names.joblib")
MODEL_PATHS = OrderedDict([
    ('Linear Regression', os.path.join(OUTPUT_DIR, "linear_regression_model.joblib")),
    ('Decision Tree', os.path.join(OUTPUT_DIR, "decision_tree_model.joblib")),
    ('Random Forest', os.path.join(OUTPUT_DIR, "random_forest_model.joblib")),
    ('XGBoost', os.path.join(OUTPUT_DIR, "xgboost_model.joblib")),
    ('MLP Regressor', os.path.join(OUTPUT_DIR, "mlp_regressor_model.joblib"))
])

# H·∫±ng s·ªë cho quy ƒë·ªïi v√† COCOMO
LOC_PER_FP_LANGUAGES = OrderedDict([
    ("3GL (Java, C#, C++)", {"avg": 55}),  # Gi√° tr·ªã v√≠ d·ª•, c·∫ßn ƒëi·ªÅu ch·ªânh theo ng·ªØ c·∫£nh
    ("4GL (SQL, RAD tools)", {"avg": 20}),
    ("Python", {"avg": 40}),
    ("JavaScript (Frontend)", {"avg": 50}),
    ("Ng√¥n ng·ªØ kh√°c/Trung b√¨nh", {"avg": 50})  # M·∫∑c ƒë·ªãnh
])
DEFAULT_LOC_PER_FP = LOC_PER_FP_LANGUAGES["Ng√¥n ng·ªØ kh√°c/Trung b√¨nh"]["avg"]

# T·ª∑ l·ªá quy ƒë·ªïi UCP v√† FP (v√≠ d·ª•: 1 UCP ~ 1.5-2.5 FP)
# Gi·∫£ s·ª≠ 1 UCP = 2 FP (UCP th∆∞·ªùng l·ªõn h∆°n FP v·ªÅ scope)
UCP_TO_FP_RATIO = 2.0
FP_TO_UCP_RATIO = 1.0 / UCP_TO_FP_RATIO

# Tham s·ªë COCOMO II (Basic Effort + TDEV)
# Effort (PM) = a * (KLOC)^b * EAF
# TDEV (Months) = c * (PM_EAF_Adjusted)^d
# L∆∞u √Ω: EAF ƒë∆∞·ª£c √°p d·ª•ng cho Effort (PM), sau ƒë√≥ PM ƒë√£ ƒëi·ªÅu ch·ªânh ƒë∆∞·ª£c d√πng cho TDEV
COCOMO_PARAMS = {
    "Organic": {"a": 2.4, "b": 1.05, "c": 2.5, "d": 0.38},
    "Semi-detached": {"a": 3.0, "b": 1.12, "c": 2.5, "d": 0.35},
    "Embedded": {"a": 3.6, "b": 1.20, "c": 2.5, "d": 0.32}
}


# --- T·∫£i Artifacts ---
@st.cache_resource
def load_all_artifacts(preprocessor_path, features_path, model_paths_dict):
    loaded_models = OrderedDict()
    preprocessor = None
    feature_names = None
    categorical_features_options = {}
    original_cols_order = []
    all_loaded_successfully = True

    if not os.path.exists(preprocessor_path):
        st.error(f"L·ªñI: Kh√¥ng t√¨m th·∫•y file preprocessor t·∫°i '{preprocessor_path}'")
        return None, None, None, None, None, False  # Th√™m c·ªù tr·∫°ng th√°i
    try:
        preprocessor = joblib.load(preprocessor_path)
        num_transformer_tuple = next(t for t in preprocessor.transformers_ if t[0] == 'num')
        cat_transformer_tuple = next(t for t in preprocessor.transformers_ if t[0] == 'cat')
        original_num_features = list(num_transformer_tuple[2])
        original_cat_features = list(cat_transformer_tuple[2])
        original_cols_order = original_num_features + original_cat_features

        cat_pipeline = preprocessor.named_transformers_['cat']
        onehot_encoder = cat_pipeline.named_steps['onehot']

        if hasattr(onehot_encoder, 'categories_') and len(onehot_encoder.categories_) == len(original_cat_features):
            for i, feature_name in enumerate(original_cat_features):
                categorical_features_options[feature_name] = onehot_encoder.categories_[i].tolist()
        else:
            st.error("L·ªói tr√≠ch xu·∫•t danh m·ª•c t·ª´ OneHotEncoder.")
            all_loaded_successfully = False
    except Exception as e_load_prep:
        st.error(f"L·ªói nghi√™m tr·ªçng khi t·∫£i preprocessor: {e_load_prep}")
        return None, None, None, None, None, False

    if not os.path.exists(features_path):
        st.error(f"L·ªñI: Kh√¥ng t√¨m th·∫•y file t√™n ƒë·∫∑c tr∆∞ng t·∫°i '{features_path}'")
        all_loaded_successfully = False
    else:
        try:
            feature_names = joblib.load(features_path)
            if isinstance(feature_names, np.ndarray): feature_names = feature_names.tolist()
        except Exception as e_load_feat:
            st.error(f"L·ªói khi t·∫£i feature names: {e_load_feat}")
            all_loaded_successfully = False

    models_actually_loaded = 0
    for name, path in model_paths_dict.items():
        if not os.path.exists(path):
            st.warning(f"C·∫£nh b√°o: Kh√¥ng t√¨m th·∫•y file m√¥ h√¨nh '{name}' t·∫°i '{path}'. B·ªè qua.")
            continue
        try:
            loaded_models[name] = joblib.load(path)
            models_actually_loaded += 1
        except Exception as e_load_model:
            st.warning(f"L·ªói khi t·∫£i m√¥ h√¨nh {name}: {e_load_model}. B·ªè qua.")

    if models_actually_loaded == 0:
        st.warning("Kh√¥ng t·∫£i ƒë∆∞·ª£c b·∫•t k·ª≥ m√¥ h√¨nh Machine Learning n√†o.")
        # all_loaded_successfully = False # V·∫´n c√≥ th·ªÉ ch·∫°y m√¥ h√¨nh truy·ªÅn th·ªëng

    return preprocessor, feature_names, loaded_models, original_cols_order, categorical_features_options, all_loaded_successfully


preprocessor, feature_names_out, ml_models, original_cols_order, categorical_features_options, artifacts_loaded_successfully = load_all_artifacts(
    PREPROCESSOR_PATH, FEATURES_PATH, MODEL_PATHS
)


# --- H√†m T√≠nh to√°n cho M√¥ h√¨nh Truy·ªÅn th·ªëng v√† Quy ƒë·ªïi ---

def get_loc_per_fp(language_choice_key):
    """L·∫•y t·ª∑ l·ªá LOC/FP d·ª±a tr√™n l·ª±a ch·ªçn ng√¥n ng·ªØ."""
    return LOC_PER_FP_LANGUAGES.get(language_choice_key, {"avg": DEFAULT_LOC_PER_FP})["avg"]


def convert_software_sizes(value, input_type, loc_per_fp_rate, ucp_fp_ratio, fp_ucp_ratio):
    """
    Quy ƒë·ªïi gi·ªØa LOC, FP, UCP.
    Tr·∫£ v·ªÅ m·ªôt dictionary: {'loc': loc_val, 'fp': fp_val, 'ucp': ucp_val}
    """
    loc_val, fp_val, ucp_val = 0, 0, 0
    if value is None or value < 0: value = 0  # X·ª≠ l√Ω gi√° tr·ªã kh√¥ng h·ª£p l·ªá

    try:
        if input_type == 'LOC':
            loc_val = float(value)
            fp_val = loc_val / loc_per_fp_rate if loc_per_fp_rate > 0 else 0
            ucp_val = fp_val * fp_ucp_ratio  # FP nh·ªè h∆°n UCP, n√™n UCP = FP / (FP/UCP_ratio) = FP * (UCP/FP_ratio)
        elif input_type == 'FP':
            fp_val = float(value)
            loc_val = fp_val * loc_per_fp_rate
            ucp_val = fp_val * fp_ucp_ratio
        elif input_type == 'UCP':
            ucp_val = float(value)
            fp_val = ucp_val * ucp_fp_ratio  # UCP to FP
            loc_val = fp_val * loc_per_fp_rate
        else:
            return {'loc': 0, 'fp': 0, 'ucp': 0, 'error': "Lo·∫°i input kh√¥ng h·ª£p l·ªá"}

        return {
            'loc': round(loc_val, 0),
            'fp': round(fp_val, 2),
            'ucp': round(ucp_val, 2),
            'error': None
        }
    except Exception as e:
        return {'loc': 0, 'fp': 0, 'ucp': 0, 'error': str(e)}


def calculate_cocomo_ii_extended(loc, mode, eaf, hrs_per_month, params):
    """
    T√≠nh to√°n Effort (PM, Person-hours), TDEV (th√°ng), v√† Staff (ng∆∞·ªùi) theo COCOMO II.
    """
    results = {
        'effort_pm': "N/A", 'effort_hrs': "N/A",
        'tdev_months': "N/A", 'avg_staff': "N/A", 'error': None
    }
    if loc <= 0:
        results['error'] = "LOC ph·∫£i > 0"
        return results
    if hrs_per_month <= 0:
        results['error'] = "S·ªë gi·ªù/th√°ng ph·∫£i > 0"
        return results
    if mode not in params:
        results['error'] = "Ch·∫ø ƒë·ªô COCOMO kh√¥ng h·ª£p l·ªá"
        return results

    kloc = loc / 1000.0
    mode_params = params[mode]
    a, b, c, d = mode_params["a"], mode_params["b"], mode_params["c"], mode_params["d"]

    try:
        # Effort (Person-Months) = a * (KLOC)^b * EAF
        effort_pm = a * (kloc ** b) * eaf
        results['effort_pm'] = round(effort_pm, 2)

        # Effort (Person-Hours)
        effort_hrs = effort_pm * hrs_per_month
        results['effort_hrs'] = round(effort_hrs, 2)

        # TDEV (Development Time in Months) = c * (Effort_PM_Adjusted_by_EAF)^d
        # EAF ƒë√£ ƒë∆∞·ª£c t√≠nh v√†o effort_pm
        tdev_months = c * (effort_pm ** d)
        results['tdev_months'] = round(tdev_months, 2)

        # Average Staffing (Persons) = Effort_PM / TDEV_Months
        if tdev_months > 0:
            avg_staff = effort_pm / tdev_months
            results['avg_staff'] = round(avg_staff, 2)
        else:
            results['avg_staff'] = "N/A (TDEV <=0)"

        return results
    except Exception as e:
        results['error'] = f"L·ªói t√≠nh to√°n COCOMO: {e}"
        return results


def calculate_fp_effort(fp, hrs_per_fp):
    if fp <= 0 or hrs_per_fp <= 0: return "L·ªói (FP ho·∫∑c Gi·ªù/FP <= 0)"
    try:
        return round(fp * hrs_per_fp, 2)
    except:
        return "L·ªói t√≠nh to√°n"


def calculate_ucp_effort(ucp, hrs_per_ucp):
    if ucp <= 0 or hrs_per_ucp <= 0: return "L·ªói (UCP ho·∫∑c Gi·ªù/UCP <= 0)"
    try:
        return round(ucp * hrs_per_ucp, 2)
    except:
        return "L·ªói t√≠nh to√°n"


# --- Giao di·ªán Nh·∫≠p li·ªáu Sidebar ---
st.sidebar.header("Nh·∫≠p Th√¥ng tin D·ª± √°n")

# M·ª•c m·ªõi cho Quy ƒë·ªïi v√† ∆Ø·ªõc t√≠nh Th·ªùi gian/Nh√¢n l·ª±c
st.sidebar.subheader("Quy ƒë·ªïi K√≠ch th∆∞·ªõc & ∆Ø·ªõc t√≠nh T.Gian/Nh√¢n l·ª±c")
primary_metric_for_conversion = st.sidebar.radio(
    "Ch·ªçn Metric ch√≠nh ƒë·ªÉ nh·∫≠p v√† quy ƒë·ªïi:",
    ('LOC', 'FP', 'UCP'),
    key='primary_metric_source',
    horizontal=True,
    index=0  # M·∫∑c ƒë·ªãnh ch·ªçn LOC
)

language_for_conversion_key = st.sidebar.selectbox(
    "Ng√¥n ng·ªØ/Lo·∫°i (cho quy ƒë·ªïi LOC-FP):",
    options=list(LOC_PER_FP_LANGUAGES.keys()),
    key="lang_type_conversion"
)

# C√°c tr∆∞·ªùng nh·∫≠p LOC, FP, UCP - gi√° tr·ªã s·∫Ω ƒë∆∞·ª£c c·∫≠p nh·∫≠t d·ª±a tr√™n primary_metric_source
# Kh·ªüi t·∫°o gi√° tr·ªã trong session_state n·∫øu ch∆∞a c√≥ ƒë·ªÉ tr√°nh l·ªói khi truy c·∫≠p l·∫ßn ƒë·∫ßu
if 'loc_input_val' not in st.session_state: st.session_state.loc_input_val = 10000
if 'fp_input_val' not in st.session_state: st.session_state.fp_input_val = 0.0  # S·∫Ω ƒë∆∞·ª£c t√≠nh
if 'ucp_input_val' not in st.session_state: st.session_state.ucp_input_val = 0.0  # S·∫Ω ƒë∆∞·ª£c t√≠nh

# S·ª≠ d·ª•ng st.session_state ƒë·ªÉ l∆∞u tr·ªØ gi√° tr·ªã ng∆∞·ªùi d√πng nh·∫≠p cho metric ch√≠nh
# v√† c√°c gi√° tr·ªã ƒë∆∞·ª£c t√≠nh to√°n cho c√°c metric kh√°c.
# ƒêi·ªÅu n√†y cho ph√©p c√°c gi√° tr·ªã ƒë∆∞·ª£c gi·ªØ l·∫°i gi·ªØa c√°c l·∫ßn ch·∫°y l·∫°i khi nh·∫•n n√∫t.

col_size1, col_size2 = st.sidebar.columns(2)
with col_size1:
    # Ch·ªâ cho ph√©p nh·∫≠p v√†o metric ƒë∆∞·ª£c ch·ªçn l√† ch√≠nh, c√°c metric kh√°c s·∫Ω hi·ªÉn th·ªã gi√° tr·ªã t√≠nh to√°n
    if st.session_state.primary_metric_source == 'LOC':
        st.session_state.loc_input_val = st.number_input("Lines of Code (LOC)", min_value=0,
                                                         value=st.session_state.loc_input_val, step=100,
                                                         key="loc_input_main")
        st.markdown(f"**FP (t√≠nh to√°n):** `{st.session_state.fp_input_val:.2f}`")
        st.markdown(f"**UCP (t√≠nh to√°n):** `{st.session_state.ucp_input_val:.2f}`")
    elif st.session_state.primary_metric_source == 'FP':
        st.session_state.fp_input_val = st.number_input("Function Points (FP)", min_value=0.0,
                                                        value=st.session_state.fp_input_val, step=1.0, format="%.2f",
                                                        key="fp_input_main")
        st.markdown(f"**LOC (t√≠nh to√°n):** `{st.session_state.loc_input_val:,.0f}`")
        st.markdown(f"**UCP (t√≠nh to√°n):** `{st.session_state.ucp_input_val:.2f}`")
    elif st.session_state.primary_metric_source == 'UCP':
        st.session_state.ucp_input_val = st.number_input("Use Case Points (UCP)", min_value=0.0,
                                                         value=st.session_state.ucp_input_val, step=1.0, format="%.2f",
                                                         key="ucp_input_main")
        st.markdown(f"**LOC (t√≠nh to√°n):** `{st.session_state.loc_input_val:,.0f}`")
        st.markdown(f"**FP (t√≠nh to√°n):** `{st.session_state.fp_input_val:.2f}`")

# C√°c tr∆∞·ªùng hi·ªÉn th·ªã cho Th·ªùi gian ph√°t tri·ªÉn v√† Team size (s·∫Ω ƒë∆∞·ª£c t√≠nh to√°n)
with col_size2:  # Ho·∫∑c m·ªôt khu v·ª±c ri√™ng
    st.markdown("**K·∫øt qu·∫£ COCOMO II (m·ªü r·ªông):**")
    st.markdown(f"T.Gian P.Tri·ªÉn (th√°ng):")
    st.markdown(
        f"<h5 style='text-align: left; color: orange;'>{st.session_state.get('cocomo_tdev_months', 'N/A')}</h5>",
        unsafe_allow_html=True)
    st.markdown(f"K.Th∆∞·ªõc ƒê·ªôi ng≈© (ng∆∞·ªùi):")
    st.markdown(f"<h5 style='text-align: left; color: orange;'>{st.session_state.get('cocomo_avg_staff', 'N/A')}</h5>",
                unsafe_allow_html=True)

# Tham s·ªë cho m√¥ h√¨nh truy·ªÅn th·ªëng (COCOMO, FP Effort, UCP Effort)
st.sidebar.subheader("Tham s·ªë cho M√¥ h√¨nh Truy·ªÅn th·ªëng")
cocomo_mode = st.sidebar.selectbox("Ch·∫ø ƒë·ªô D·ª± √°n COCOMO", ["Organic", "Semi-detached", "Embedded"], key="cocomo_mode")
eaf = st.sidebar.number_input("H·ªá s·ªë ƒêi·ªÅu ch·ªânh N·ªó l·ª±c COCOMO (EAF)", min_value=0.1, value=1.0, step=0.1, format="%.2f",
                              key="eaf")
hours_per_month = st.sidebar.number_input("S·ªë gi·ªù l√†m vi·ªác/th√°ng (quy ƒë·ªïi)", min_value=1, value=152, step=8,
                                          key="hrs_month")

st.sidebar.markdown("**Function Points (FP) Effort**")
hours_per_fp = st.sidebar.number_input("S·ªë gi·ªù/Function Point (NƒÉng su·∫•t)", min_value=0.1, value=10.0, step=0.5,
                                       format="%.1f", key="hrs_fp")

st.sidebar.markdown("**Use Case Points (UCP) Effort**")
hours_per_ucp = st.sidebar.number_input("S·ªë gi·ªù/Use Case Point (NƒÉng su·∫•t)", min_value=0.1, value=20.0, step=1.0,
                                        format="%.1f", key="hrs_ucp")

# Input cho ML (n·∫øu c√≥)
input_values_ml = {}  # Dictionary ri√™ng cho ML features
if artifacts_loaded_successfully and preprocessor and original_cols_order and categorical_features_options:
    st.sidebar.subheader("ƒê·∫∑c tr∆∞ng B·ªï sung (cho ML)")
    # V√≠ d·ª•: n·∫øu ML model c·ªßa b·∫°n c√≥ c√°c feature n√†y
    # Ch√∫ng ta s·∫Ω kh√¥ng t·ª± ƒë·ªông ƒëi·ªÅn 'Development Time (months)' v√† 'Team Size' t·ª´ COCOMO v√†o ƒë√¢y
    # tr·ª´ khi ƒë√≥ l√† m·ªôt ph·∫ßn c·ªßa thi·∫øt k·∫ø feature engineering c·ªßa b·∫°n.
    # Hi·ªán t·∫°i, ch√∫ng ta coi ch√∫ng l√† output c·ªßa COCOMO, kh√¥ng ph·∫£i input cho ML.
    if 'Development Time (months)' in original_cols_order:
        input_values_ml['Development Time (months)'] = st.sidebar.number_input("ML: Development Time (months)",
                                                                               min_value=1, value=6, step=1,
                                                                               key="ml_dev_time")
    if 'Team Size' in original_cols_order:
        input_values_ml['Team Size'] = st.sidebar.number_input("ML: Team Size", min_value=1, value=5, step=1,
                                                               key="ml_team_size")

    # C√°c input ph√¢n lo·∫°i cho ML
    if any(col in original_cols_order for col in categorical_features_options.keys()):
        st.sidebar.subheader("Th√¥ng tin Ph√¢n lo·∫°i (cho ML)")
        col_cat_ml1, col_cat_ml2 = st.sidebar.columns(2)
        cat_cols_for_ml = [col for col in original_cols_order if col in categorical_features_options]

        with col_cat_ml1:
            for i, col_name in enumerate(cat_cols_for_ml):
                if i < len(cat_cols_for_ml) / 2:
                    options = categorical_features_options[col_name]
                    input_values_ml[col_name] = st.selectbox(f"ML: {col_name}", options=options, index=0,
                                                             key=f"ml_sb_{col_name}_1")
        with col_cat_ml2:
            for i, col_name in enumerate(cat_cols_for_ml):
                if i >= len(cat_cols_for_ml) / 2:
                    options = categorical_features_options[col_name]
                    input_values_ml[col_name] = st.selectbox(f"ML: {col_name}", options=options, index=0,
                                                             key=f"ml_sb_{col_name}_2")
else:
    st.sidebar.warning("ML: Kh√¥ng th·ªÉ t·∫£i preprocessor ho·∫∑c th√¥ng tin c·ªôt. Ph·∫ßn nh·∫≠p li·ªáu ML b·ªã h·∫°n ch·∫ø.")

# --- N√∫t D·ª± ƒëo√°n/T√≠nh to√°n ---
calculate_button = st.sidebar.button("üìä ∆Ø·ªõc t√≠nh & So s√°nh Effort", use_container_width=True, type="primary")

# --- X·ª≠ l√Ω v√† Hi·ªÉn th·ªã K·∫øt qu·∫£ ---
if calculate_button:
    st.divider()
    st.subheader("üìä K·∫øt qu·∫£ ∆Ø·ªõc t√≠nh T·ªïng h·ª£p")

    # 1. Th·ª±c hi·ªán quy ƒë·ªïi k√≠ch th∆∞·ªõc d·ª±a tr√™n l·ª±a ch·ªçn c·ªßa ng∆∞·ªùi d√πng
    primary_metric_type = st.session_state.primary_metric_source
    primary_value = 0
    if primary_metric_type == 'LOC':
        primary_value = st.session_state.loc_input_val
    elif primary_metric_type == 'FP':
        primary_value = st.session_state.fp_input_val
    elif primary_metric_type == 'UCP':
        primary_value = st.session_state.ucp_input_val

    selected_loc_per_fp = get_loc_per_fp(st.session_state.lang_type_conversion)

    converted_sizes = convert_software_sizes(
        primary_value,
        primary_metric_type,
        selected_loc_per_fp,
        UCP_TO_FP_RATIO,
        FP_TO_UCP_RATIO
    )

    if converted_sizes['error']:
        st.error(f"L·ªói quy ƒë·ªïi k√≠ch th∆∞·ªõc: {converted_sizes['error']}")
        st.stop()

    # C·∫≠p nh·∫≠t session_state v·ªõi c√°c gi√° tr·ªã ƒë√£ quy ƒë·ªïi ƒë·ªÉ hi·ªÉn th·ªã l·∫°i tr√™n sidebar
    st.session_state.loc_input_val = converted_sizes['loc']
    st.session_state.fp_input_val = converted_sizes['fp']
    st.session_state.ucp_input_val = converted_sizes['ucp']

    # G√°n gi√° tr·ªã ƒë√£ quy ƒë·ªïi ƒë·ªÉ s·ª≠ d·ª•ng trong c√°c t√≠nh to√°n ti·∫øp theo
    current_loc = converted_sizes['loc']
    current_fp = converted_sizes['fp']
    current_ucp = converted_sizes['ucp']

    st.markdown(f"**Th√¥ng tin K√≠ch th∆∞·ªõc ƒë√£ Quy ƒë·ªïi (s·ª≠ d·ª•ng cho c√°c ∆∞·ªõc t√≠nh):**")
    st.markdown(f"- **LOC:** `{current_loc:,.0f}`")
    st.markdown(
        f"- **FP:** `{current_fp:.2f}` (t·ª´ {primary_metric_type}={primary_value} v·ªõi Ng√¥n ng·ªØ: {st.session_state.lang_type_conversion}, LOC/FP={selected_loc_per_fp})")
    st.markdown(
        f"- **UCP:** `{current_ucp:.2f}` (t·ª´ {primary_metric_type}={primary_value} v·ªõi UCP/FP Ratio={UCP_TO_FP_RATIO})")

    all_results = OrderedDict()
    error_messages_ml = {}

    # --- 2. T√≠nh to√°n t·ª´ M√¥ h√¨nh Truy·ªÅn th·ªëng (s·ª≠ d·ª•ng gi√° tr·ªã ƒë√£ quy ƒë·ªïi) ---
    st.markdown("#### A. ∆Ø·ªõc t√≠nh t·ª´ M√¥ h√¨nh Truy·ªÅn th·ªëng")
    traditional_captions = []

    # COCOMO II Extended (Effort, TDEV, Staff)
    cocomo_results = calculate_cocomo_ii_extended(current_loc, cocomo_mode, eaf, hours_per_month, COCOMO_PARAMS)
    if cocomo_results['error']:
        st.error(f"L·ªói COCOMO II: {cocomo_results['error']}")
        all_results['COCOMO II (Effort)'] = "L·ªói"
        st.session_state.cocomo_tdev_months = "L·ªói"
        st.session_state.cocomo_avg_staff = "L·ªói"
    else:
        all_results['COCOMO II (Effort)'] = cocomo_results['effort_hrs']
        st.session_state.cocomo_tdev_months = cocomo_results['tdev_months']
        st.session_state.cocomo_avg_staff = cocomo_results['avg_staff']
        traditional_captions.append(
            f"* **COCOMO II:** Mode={cocomo_mode}, LOC={current_loc:,.0f}, EAF={eaf}, Hrs/Month={hours_per_month} "
            f"-> Effort PM={cocomo_results['effort_pm']}, TDEV={cocomo_results['tdev_months']} th√°ng, Staff={cocomo_results['avg_staff']} ng∆∞·ªùi."
        )

    # Function Points Effort
    fp_effort = calculate_fp_effort(current_fp, hours_per_fp)
    all_results['Function Points (Effort)'] = fp_effort
    traditional_captions.append(f"* **Function Points Effort:** FP={current_fp:.2f}, Hours/FP={hours_per_fp}")

    # Use Case Points Effort
    ucp_effort = calculate_ucp_effort(current_ucp, hours_per_ucp)
    all_results['Use Case Points (Effort)'] = ucp_effort
    traditional_captions.append(f"* **Use Case Points Effort:** UCP={current_ucp:.2f}, Hours/UCP={hours_per_ucp}")

    st.markdown("**Tham s·ªë v√† K·∫øt qu·∫£ Chi ti·∫øt (Truy·ªÅn th·ªëng):**")
    for caption in traditional_captions:
        st.markdown(caption)
    st.caption("L∆∞u √Ω: Effort ƒë∆∞·ª£c t√≠nh b·∫±ng person-hours. 'L·ªói' xu·∫•t hi·ªán n·∫øu ƒë·∫ßu v√†o kh√¥ng h·ª£p l·ªá.")

    # --- 3. D·ª± ƒëo√°n t·ª´ M√¥ h√¨nh Machine Learning ---
    if artifacts_loaded_successfully and preprocessor and feature_names_out and ml_models and original_cols_order and categorical_features_options:
        st.markdown("#### B. D·ª± ƒëo√°n t·ª´ M√¥ h√¨nh Machine Learning")

        # Chu·∫©n b·ªã input_df_ml. C·∫ßn ƒë·∫£m b·∫£o c√°c c·ªôt 'LOC', 'FP', 'UCP' (n·∫øu c√≥ trong ML model)
        # s·ª≠ d·ª•ng c√°c gi√° tr·ªã ƒë√£ quy ƒë·ªïi (current_loc, current_fp, current_ucp).
        # C√°c gi√° tr·ªã kh√°c l·∫•y t·ª´ input_values_ml.

        ml_input_data_prepared = {}
        for col in original_cols_order:
            if col == 'LOC':
                ml_input_data_prepared[col] = current_loc
            elif col == 'FP':
                ml_input_data_prepared[col] = current_fp
            elif col == 'UCP':
                ml_input_data_prepared[col] = current_ucp
            elif col in input_values_ml:  # C√°c feature kh√°c c·ªßa ML
                ml_input_data_prepared[col] = input_values_ml[col]
            else:
                # N·∫øu c·ªôt ML kh√¥ng ph·∫£i LOC/FP/UCP v√† c≈©ng kh√¥ng c√≥ input ri√™ng,
                # c√≥ th·ªÉ c·∫ßn gi√° tr·ªã m·∫∑c ƒë·ªãnh ho·∫∑c b√°o l·ªói.
                # Hi·ªán t·∫°i, preprocessor s·∫Ω x·ª≠ l√Ω SimpleImputer n·∫øu thi·∫øu.
                ml_input_data_prepared[col] = np.nan
                st.warning(f"ML Input: Thi·∫øu gi√° tr·ªã cho '{col}', s·∫Ω ƒë∆∞·ª£c imputer x·ª≠ l√Ω (n·∫øu c√≥).")

        try:
            input_df_ml = pd.DataFrame([ml_input_data_prepared], columns=original_cols_order)
            input_processed_np = preprocessor.transform(input_df_ml)

            if isinstance(feature_names_out, list) and len(feature_names_out) == input_processed_np.shape[1]:
                input_processed_df = pd.DataFrame(input_processed_np, columns=feature_names_out)
                for model_name, loaded_model in ml_models.items():
                    try:
                        pred = loaded_model.predict(input_processed_df)
                        prediction_value = float(pred[0]) if pred.size > 0 else 0.0
                        all_results[f"ML: {model_name}"] = max(0.0, round(prediction_value, 2))
                    except Exception as model_pred_e:
                        error_msg = f"L·ªói d·ª± ƒëo√°n {model_name}: {str(model_pred_e)}"
                        st.error(error_msg)
                        all_results[f"ML: {model_name}"] = "L·ªói"
                        error_messages_ml[model_name] = str(model_pred_e)
            else:
                st.error(
                    f"L·ªói ML: S·ªë t√™n ƒë·∫∑c tr∆∞ng ({len(feature_names_out)}) kh√¥ng kh·ªõp s·ªë c·ªôt sau transform ({input_processed_np.shape[1]}).")
                for model_name in ml_models.keys(): all_results[f"ML: {model_name}"] = "L·ªói (Config)"
        except Exception as e_ml_process:
            st.error(f"L·ªói x·ª≠ l√Ω/d·ª± ƒëo√°n ML: {e_ml_process}")
            # traceback.print_exc() # In ra console server
            for model_name in ml_models.keys(): all_results[f"ML: {model_name}"] = "L·ªói (Process)"
    else:
        st.info("Ph·∫ßn d·ª± ƒëo√°n Machine Learning kh√¥ng th·ª±c hi·ªán do thi·∫øu th√†nh ph·∫ßn.")

    # --- 4. Hi·ªÉn th·ªã B·∫£ng v√† Bi·ªÉu ƒë·ªì So s√°nh T·ªïng h·ª£p ---
    st.markdown("#### C. B·∫£ng v√† Bi·ªÉu ƒë·ªì So s√°nh Effort (person-hours)")
    if all_results:
        result_list = [{'M√¥ H√¨nh ∆Ø·ªõc T√≠nh': name, 'Effort D·ª± ƒëo√°n (person-hours)': effort} for name, effort in
                       all_results.items()]
        result_df = pd.DataFrame(result_list)


        def format_effort_display(x):
            if isinstance(x, (int, float)): return f"{x:,.2f}"
            return str(x)


        st.dataframe(
            result_df.style.format({'Effort D·ª± ƒëo√°n (person-hours)': format_effort_display}),
            use_container_width=True, hide_index=True
        )

        st.write("Bi·ªÉu ƒë·ªì so s√°nh Effort:")
        try:
            chart_df = result_df.copy()
            chart_df['Effort D·ª± ƒëo√°n (person-hours)'] = chart_df['Effort D·ª± ƒëo√°n (person-hours)'].astype(
                str).str.replace(',', '', regex=False)
            chart_df['Effort D·ª± ƒëo√°n (person-hours)'] = pd.to_numeric(chart_df['Effort D·ª± ƒëo√°n (person-hours)'],
                                                                      errors='coerce')
            chart_df.dropna(subset=['Effort D·ª± ƒëo√°n (person-hours)'], inplace=True)

            if not chart_df.empty:
                chart_data = chart_df.set_index('M√¥ H√¨nh ∆Ø·ªõc T√≠nh')['Effort D·ª± ƒëo√°n (person-hours)']
                st.bar_chart(chart_data)
            else:
                st.info("Kh√¥ng c√≥ d·ª± ƒëo√°n effort h·ª£p l·ªá ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì.")
        except Exception as chart_e:
            st.warning(f"Kh√¥ng th·ªÉ v·∫Ω bi·ªÉu ƒë·ªì: {chart_e}")
            # traceback.print_exc()

    if error_messages_ml:
        st.subheader("‚ö†Ô∏è Chi ti·∫øt l·ªói d·ª± ƒëo√°n ML:")
        for model_name, msg in error_messages_ml.items():
            st.caption(f"**{model_name}:** {msg}")

    st.info("""
    **L∆∞u √Ω quan tr·ªçng:**
    * K·∫øt qu·∫£ t·ª´ c√°c m√¥ h√¨nh ch·ªâ l√† **∆∞·ªõc t√≠nh**. Effort th·ª±c t·∫ø c√≥ th·ªÉ kh√°c bi·ªát.
    * ƒê·ªô ch√≠nh x√°c ph·ª• thu·ªôc v√†o ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu hu·∫•n luy·ªán (ML) v√† l·ª±a ch·ªçn tham s·ªë (truy·ªÅn th·ªëng).
    * H√£y s·ª≠ d·ª•ng k·∫øt qu·∫£ n√†y nh∆∞ m·ªôt ƒëi·ªÉm tham kh·∫£o.
    """)
    # Force a rerun to update sidebar display with new calculated values
    st.experimental_rerun()

# --- X·ª≠ l√Ω tr∆∞·ªùng h·ª£p kh√¥ng t·∫£i ƒë∆∞·ª£c artifacts ban ƒë·∫ßu ---
if not calculate_button and not artifacts_loaded_successfully:  # Ch·ªâ hi·ªÉn th·ªã n·∫øu ch∆∞a nh·∫•n n√∫t v√† c√≥ l·ªói load
    if not ml_models and not preprocessor:
        st.error("Kh√¥ng th·ªÉ t·∫£i c√°c th√†nh ph·∫ßn cho d·ª± ƒëo√°n Machine Learning.")
    elif not ml_models:
        st.warning("Kh√¥ng t·∫£i ƒë∆∞·ª£c m√¥ h√¨nh ML. Ch·ªâ c√≥ th·ªÉ d√πng m√¥ h√¨nh truy·ªÅn th·ªëng.")
    elif not preprocessor or not feature_names_out or not original_cols_order or not categorical_features_options:
        st.error("Kh√¥ng th·ªÉ t·∫£i preprocessor/th√¥ng tin ƒë·∫∑c tr∆∞ng cho ML.")

# --- Ch√¢n trang ---
st.markdown("---")
st.caption("·ª®ng d·ª•ng demo ƒë∆∞·ª£c x√¢y d·ª±ng v·ªõi Streamlit, Scikit-learn, XGBoost v√† c√°c m√¥ h√¨nh ∆∞·ªõc t√≠nh truy·ªÅn th·ªëng.")
