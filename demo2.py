# -*- coding: utf-8 -*-
"""
app.py: ·ª®ng d·ª•ng Web Streamlit ƒë·ªÉ d·ª± ƒëo√°n Effort, Th·ªùi gian v√† Quy m√¥ ƒë·ªôi
(Phi√™n b·∫£n c√≥ ch·ªçn ng√¥n ng·ªØ cho LOC/FP, ·∫©n ML extras n·∫øu kh√¥ng c·∫ßn).
"""

import streamlit as st
import pandas as pd
import numpy as np
import joblib
import os
from collections import OrderedDict
import math  # C·∫ßn cho COCOMO
import traceback  # Th√™m ƒë·ªÉ in l·ªói chi ti·∫øt

# Import c√°c l·ªõp c·∫ßn thi·∫øt
try:
    from sklearn.compose import ColumnTransformer
    from sklearn.pipeline import Pipeline
    from sklearn.impute import SimpleImputer
    from sklearn.preprocessing import RobustScaler, OneHotEncoder
    from sklearn.linear_model import LinearRegression
    from sklearn.tree import DecisionTreeRegressor
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.neural_network import MLPRegressor
    import xgboost as xgb
except ImportError as e:
    st.error(f"L·ªói Import th∆∞ vi·ªán: {e}. H√£y ƒë·∫£m b·∫£o c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t.")
    st.stop()

# --- H·∫±ng s·ªë cho nƒÉng su·∫•t m·∫∑c ƒë·ªãnh ---
HOURS_PER_FP_DEFAULT = 10.0
HOURS_PER_UCP_DEFAULT = 20.0

# --- ƒê·ªãnh nghƒ©a c√°c Ng√¥n ng·ªØ v√† LOC/FP t∆∞∆°ng ·ª©ng ---
LANGUAGE_LOC_FP_MAP = OrderedDict([
    ("Java (3GL)", 53),
    ("C# (3GL)", 54),
    ("C++ (3GL)", 60),  # Th√™m v√≠ d·ª•
    ("Python (3GL/Scripting)", 35),
    ("JavaScript (3GL/Scripting)", 47),
    ("PHP (Scripting)", 40),  # Th√™m v√≠ d·ª•
    ("SQL (4GL)", 15),
    ("Oracle Forms (4GL)", 20),
    ("PowerBuilder (4GL)", 16),  # Th√™m v√≠ d·ª•
    ("Trung b√¨nh 3GL", 65),  # Gi√° tr·ªã tham kh·∫£o chung
    ("Trung b√¨nh 4GL", 20),  # Gi√° tr·ªã tham kh·∫£o chung
    ("T√πy ch·ªânh", None)  # Cho ph√©p nh·∫≠p tay
])

# --- C·∫•u h√¨nh Trang v√† T·∫£i Artifacts ---
st.set_page_config(page_title="∆Ø·ªõc t√≠nh Effort, Th·ªùi gian & ƒê·ªôi ng≈© Ph·∫ßn m·ªÅm", layout="wide")

st.title("·ª®ng d·ª•ng So s√°nh ∆Ø·ªõc t√≠nh Effort, Th·ªùi gian & ƒê·ªôi ng≈© Ph·∫ßn m·ªÅm üìä")
st.write("""
Nh·∫≠p th√¥ng tin d·ª± √°n ƒë·ªÉ nh·∫≠n ∆∞·ªõc t√≠nh effort (person-hours), th·ªùi gian ph√°t tri·ªÉn (th√°ng)
v√† quy m√¥ ƒë·ªôi ng≈© t·ª´ nhi·ªÅu m√¥ h√¨nh.
""")

OUTPUT_DIR = "."
PREPROCESSOR_PATH = os.path.join(OUTPUT_DIR, "preprocessor.joblib")
FEATURES_PATH = os.path.join(OUTPUT_DIR, "feature_names.joblib")
MODEL_PATHS = OrderedDict([
    ('Linear Regression', os.path.join(OUTPUT_DIR, "linear_regression_model.joblib")),
    ('Decision Tree', os.path.join(OUTPUT_DIR, "decision_tree_model.joblib")),
    ('Random Forest', os.path.join(OUTPUT_DIR, "random_forest_model.joblib")),
    ('XGBoost', os.path.join(OUTPUT_DIR, "xgboost_model.joblib")),
    ('MLP Regressor', os.path.join(OUTPUT_DIR, "mlp_regressor_model.joblib"))
])


@st.cache_resource
def load_all_artifacts(preprocessor_path, features_path, model_paths_dict):
    loaded_models = OrderedDict()
    preprocessor = None
    feature_names = None
    categorical_features_options = {}
    original_cols_order = []
    all_loaded_successfully = True

    if not os.path.exists(preprocessor_path):
        st.error(f"L·ªñI: Kh√¥ng t√¨m th·∫•y file preprocessor t·∫°i '{preprocessor_path}'")
        return None, None, None, None, None
    try:
        preprocessor = joblib.load(preprocessor_path)
        try:
            num_transformer_tuple = next(t for t in preprocessor.transformers_ if t[0] == 'num')
            cat_transformer_tuple = next(t for t in preprocessor.transformers_ if t[0] == 'cat')
            original_num_features = list(num_transformer_tuple[2])
            original_cat_features = list(cat_transformer_tuple[2])
            original_cols_order = original_num_features + original_cat_features

            cat_pipeline = preprocessor.named_transformers_['cat']
            onehot_encoder = cat_pipeline.named_steps['onehot']

            if hasattr(onehot_encoder, 'categories_'):
                if len(onehot_encoder.categories_) == len(original_cat_features):
                    for i, feature_name in enumerate(original_cat_features):
                        categories = onehot_encoder.categories_[i]
                        categorical_features_options[feature_name] = categories.tolist()
                else:
                    all_loaded_successfully = False
            else:
                all_loaded_successfully = False
        except Exception:
            all_loaded_successfully = False
    except Exception:
        return None, None, None, None, None

    if not os.path.exists(features_path):
        all_loaded_successfully = False
    else:
        try:
            feature_names = joblib.load(features_path)
            if isinstance(feature_names, np.ndarray): feature_names = feature_names.tolist()
            if not isinstance(feature_names, list):
                try:
                    feature_names = list(feature_names)
                except TypeError:
                    all_loaded_successfully = False
        except Exception:
            all_loaded_successfully = False

    models_actually_loaded = 0
    for name, path in model_paths_dict.items():
        if not os.path.exists(path): continue
        try:
            model = joblib.load(path)
            loaded_models[name] = model
            models_actually_loaded += 1
        except Exception:
            pass

    if all_loaded_successfully and preprocessor and feature_names and original_cols_order and categorical_features_options:
        return preprocessor, feature_names, loaded_models, original_cols_order, categorical_features_options
    else:
        return preprocessor, feature_names, loaded_models, original_cols_order, categorical_features_options


preprocessor, feature_names_out, ml_models, original_cols_order, categorical_features_options = load_all_artifacts(
    PREPROCESSOR_PATH, FEATURES_PATH, MODEL_PATHS
)


def calculate_cocomo_basic(loc, mode, eaf, hrs_per_month_cocomo):
    if loc <= 0: return "L·ªói (LOC <= 0)"
    if hrs_per_month_cocomo <= 0: return "L·ªói (Gi·ªù/Th√°ng COCOMO <= 0)"
    kloc = loc / 1000.0
    params = {"Organic": {"a": 2.4, "b": 1.05}, "Semi-detached": {"a": 3.0, "b": 1.12},
              "Embedded": {"a": 3.6, "b": 1.20}}
    if mode not in params: return "L·ªói (Ch·∫ø ƒë·ªô kh√¥ng h·ª£p l·ªá)"
    a, b = params[mode]["a"], params[mode]["b"]
    try:
        person_months = a * (kloc ** b) * eaf
        person_hours = person_months * hrs_per_month_cocomo
        return max(0.0, round(person_hours, 2))
    except Exception as e:
        return f"L·ªói t√≠nh to√°n COCOMO: {e}"


def calculate_fp_effort(fp):
    if fp <= 0: return "L·ªói (FP <= 0)"
    if HOURS_PER_FP_DEFAULT <= 0: return "L·ªói (NƒÉng su·∫•t FP m·∫∑c ƒë·ªãnh <= 0)"
    try:
        person_hours = fp * HOURS_PER_FP_DEFAULT
        return max(0.0, round(person_hours, 2))
    except Exception as e:
        return f"L·ªói t√≠nh to√°n FP: {e}"


def calculate_ucp_effort(ucp):
    if ucp <= 0: return "L·ªói (UCP <= 0)"
    if HOURS_PER_UCP_DEFAULT <= 0: return "L·ªói (NƒÉng su·∫•t UCP m·∫∑c ƒë·ªãnh <= 0)"
    try:
        person_hours = ucp * HOURS_PER_UCP_DEFAULT
        return max(0.0, round(person_hours, 2))
    except Exception as e:
        return f"L·ªói t√≠nh to√°n UCP: {e}"


st.sidebar.header("üìù Nh·∫≠p Th√¥ng tin D·ª± √°n")
input_values_ml_extra = {}

st.sidebar.subheader("üìè Ch·ªâ s·ªë K√≠ch th∆∞·ªõc & Chuy·ªÉn ƒë·ªïi")
primary_metric_type = st.sidebar.radio(
    "Ch·ªçn ch·ªâ s·ªë ƒë·∫ßu v√†o ch√≠nh:",
    ("LOC", "FP", "UCP"), key="primary_metric_type", horizontal=True
)

primary_metric_val = 0
if primary_metric_type == "LOC":
    primary_metric_val = st.sidebar.number_input("Gi√° tr·ªã Lines of Code (LOC):", min_value=0, value=10000, step=100,
                                                 key="loc_primary_input")
elif primary_metric_type == "FP":
    primary_metric_val = st.sidebar.number_input("Gi√° tr·ªã Function Points (FP):", min_value=0, value=100, step=10,
                                                 key="fp_primary_input")
else:
    primary_metric_val = st.sidebar.number_input("Gi√° tr·ªã Use Case Points (UCP):", min_value=0.0, value=100.0,
                                                 step=10.0, format="%.2f", key="ucp_primary_input")

st.sidebar.markdown("H·ªá s·ªë chuy·ªÉn ƒë·ªïi LOC/FP:")
selected_language_profile = st.sidebar.selectbox(
    "Ng√¥n ng·ªØ l·∫≠p tr√¨nh / Lo·∫°i (ƒë·ªÉ ∆∞·ªõc t√≠nh LOC/FP):",
    options=list(LANGUAGE_LOC_FP_MAP.keys()),
    index=0,  # M·∫∑c ƒë·ªãnh ch·ªçn c√°i ƒë·∫ßu ti√™n
    key="lang_profile"
)

loc_per_fp_factor_to_use = LANGUAGE_LOC_FP_MAP[selected_language_profile]
if loc_per_fp_factor_to_use is None:  # Tr∆∞·ªùng h·ª£p "T√πy ch·ªânh"
    loc_per_fp_factor_to_use = st.sidebar.number_input(
        "Nh·∫≠p S·ªë LOC trung b√¨nh / 1 FP:",
        min_value=1.0, value=50.0, step=1.0, format="%.1f", key="loc_per_fp_manual"
    )
else:
    st.sidebar.text_input(
        "S·ªë LOC trung b√¨nh / 1 FP (t·ª´ ng√¥n ng·ªØ):",
        value=f"{loc_per_fp_factor_to_use}",
        disabled=True
    )

fp_per_ucp_factor = st.sidebar.number_input(
    "S·ªë FP trung b√¨nh / 1 UCP (v√≠ d·ª•: 1.5 - 3.0):",
    min_value=0.1, value=2.0, step=0.1, format="%.1f", key="fp_per_ucp"
)

# --- 2. Widget nh·∫≠p li·ªáu ch·ªâ cho ML (ƒê·∫∑c tr∆∞ng b·ªï sung - ch·ªâ hi·ªÉn th·ªã n·∫øu c·∫ßn) ---
# X√°c ƒë·ªãnh xem c√≥ ƒë·∫∑c tr∆∞ng ML b·ªï sung n√†o c·∫ßn hi·ªÉn th·ªã kh√¥ng
supplementary_numeric_ml_features_needed = []
supplementary_categorical_ml_features_needed = []

if preprocessor and original_cols_order:
    # C√°c ƒë·∫∑c tr∆∞ng s·ªë b·ªï sung ti·ªÅm nƒÉng (kh√¥ng ph·∫£i LOC/FP/UCP)
    potential_numeric_extras = ['Development Time (months)', 'Team Size']  # Th√™m c√°c feature kh√°c n·∫øu c√≥
    for feat_name in potential_numeric_extras:
        if feat_name in original_cols_order and (
                categorical_features_options is None or feat_name not in categorical_features_options.keys()):
            supplementary_numeric_ml_features_needed.append(feat_name)

    # C√°c ƒë·∫∑c tr∆∞ng ph√¢n lo·∫°i b·ªï sung ti·ªÅm nƒÉng (v√≠ d·ª•: 'Project Type', 'Complexity Level' n·∫øu ML model d√πng)
    # Gi·∫£ s·ª≠ original_cols_order v√† categorical_features_options ƒë√£ ƒë√∫ng t·ª´ preprocessor
    if categorical_features_options:
        for cat_feat_name in categorical_features_options.keys():
            if cat_feat_name in original_cols_order:  # ƒê·∫£m b·∫£o feature n√†y th·ª±c s·ª± ƒë∆∞·ª£c preprocessor s·ª≠ d·ª•ng
                # Quy·∫øt ƒë·ªãnh xem feature n√†y c√≥ ph·∫£i l√† "b·ªï sung" hay kh√¥ng
                # V√≠ d·ª•, n·∫øu b·∫°n c√≥ 1 feature 'Deployment Environment' m√† kh√¥ng ph·∫£i l√† 1 trong c√°c input ch√≠nh kh√°c
                # if cat_feat_name not in ['Some_Primary_Categorical_Input_Handled_Elsewhere']:
                supplementary_categorical_ml_features_needed.append(cat_feat_name)

show_ml_extra_section = bool(supplementary_numeric_ml_features_needed or supplementary_categorical_ml_features_needed)

if show_ml_extra_section:
    st.sidebar.subheader("‚öôÔ∏è ƒê·∫∑c tr∆∞ng B·ªï sung (Cho ML n·∫øu m√¥ h√¨nh y√™u c·∫ßu)")
    if supplementary_numeric_ml_features_needed:
        col_ml_num1, col_ml_num2 = st.sidebar.columns(2)
        # Hi·ªÉn th·ªã c√°c input s·ªë b·ªï sung
        # V√≠ d·ª• cho 'Development Time (months)' v√† 'Team Size' n·∫øu ch√∫ng n·∫±m trong supplementary_numeric_ml_features_needed
        # C·∫ßn l√†m cho ph·∫ßn n√†y linh ƒë·ªông h∆°n n·∫øu c√≥ nhi·ªÅu feature s·ªë b·ªï sung
        with col_ml_num1:
            if 'Development Time (months)' in supplementary_numeric_ml_features_needed:
                input_values_ml_extra['Development Time (months)'] = st.number_input(
                    "Dev Time (th√°ng) (ML Feature)", min_value=1, value=6, step=1, key="ml_dev_time_feature_input"
                )
        with col_ml_num2:
            if 'Team Size' in supplementary_numeric_ml_features_needed:
                input_values_ml_extra['Team Size'] = st.number_input(
                    "Team Size (ng∆∞·ªùi) (ML Feature)", min_value=1, value=5, step=1, key="ml_team_size_feature_input"
                )
        # Th√™m c√°c input s·ªë kh√°c t∆∞∆°ng t·ª± n·∫øu c·∫ßn

    if supplementary_categorical_ml_features_needed:
        st.sidebar.markdown("**Th√¥ng tin Ph√¢n lo·∫°i B·ªï sung (Cho ML):**")  # Ti√™u ƒë·ªÅ con n·∫øu c√≥
        col_cat_ml1, col_cat_ml2 = st.sidebar.columns(2)
        half_len_cat_extra = (len(supplementary_categorical_ml_features_needed) + 1) // 2

        current_cat_list = supplementary_categorical_ml_features_needed  # S·ª≠ d·ª•ng list ƒë√£ l·ªçc

        with col_cat_ml1:
            for i, col_name in enumerate(current_cat_list[:half_len_cat_extra]):
                if col_name in categorical_features_options:  # Double check
                    options = categorical_features_options[col_name]
                    input_values_ml_extra[col_name] = st.selectbox(
                        f"{col_name}", options=options, index=0, key=f"sb_extra_{col_name}_1_ml"
                    )
        with col_cat_ml2:
            for i, col_name in enumerate(current_cat_list[half_len_cat_extra:]):
                if col_name in categorical_features_options:  # Double check
                    options = categorical_features_options[col_name]
                    input_values_ml_extra[col_name] = st.selectbox(
                        f"{col_name}", options=options, index=0, key=f"sb_extra_{col_name}_2_ml"
                    )
# else:
# st.sidebar.info("Kh√¥ng c√≥ ƒë·∫∑c tr∆∞ng ML b·ªï sung n√†o ƒë∆∞·ª£c y√™u c·∫ßu b·ªüi m√¥ h√¨nh ƒë√£ t·∫£i.")


st.sidebar.subheader("üìú Tham s·ªë cho COCOMO II (Basic)")
cocomo_mode = st.sidebar.selectbox("Ch·∫ø ƒë·ªô D·ª± √°n COCOMO", ["Organic", "Semi-detached", "Embedded"], key="cocomo_mode")
eaf = st.sidebar.number_input("H·ªá s·ªë ƒêi·ªÅu ch·ªânh N·ªó l·ª±c COCOMO (EAF)", min_value=0.1, value=1.0, step=0.1, format="%.2f",
                              key="eaf")
hours_per_month_cocomo = st.sidebar.number_input("S·ªë gi·ªù/th√°ng (COCOMO PM to PH)", min_value=1, value=152, step=8,
                                                 key="hrs_month_cocomo")

st.sidebar.subheader("‚è±Ô∏è ∆Ø·ªõc t√≠nh Th·ªùi gian & ƒê·ªôi ng≈© (L·∫≠p k·∫ø ho·∫°ch)")
scheduling_basis = st.sidebar.radio(
    "T√≠nh to√°n d·ª±a tr√™n:",
    ("Quy m√¥ ƒë·ªôi ng≈© ƒë√£ bi·∫øt", "Th·ªùi gian ph√°t tri·ªÉn mong mu·ªën"), key="scheduling_basis", horizontal=True
)
team_size_input_sched = None
dev_time_input_sched = None
if scheduling_basis == "Quy m√¥ ƒë·ªôi ng≈© ƒë√£ bi·∫øt":
    team_size_input_sched = st.sidebar.number_input("Quy m√¥ ƒë·ªôi ng≈© (s·ªë ng∆∞·ªùi)", min_value=1, value=5, step=1,
                                                    key="team_size_for_sched")
else:
    dev_time_input_sched = st.sidebar.number_input("Th·ªùi gian ph√°t tri·ªÉn mong mu·ªën (th√°ng)", min_value=1.0, value=6.0,
                                                   step=0.5, format="%.1f", key="dev_time_for_sched")

effective_hours_per_month_sched = st.sidebar.number_input(
    "S·ªë gi·ªù l√†m vi·ªác hi·ªáu qu·∫£/ng∆∞·ªùi/th√°ng (cho l·∫≠p k·∫ø ho·∫°ch)",
    min_value=1, value=140, step=8, key="eff_hrs_month_sched",
    help="V√≠ d·ª•: 8 gi·ªù/ng√†y * 20 ng√†y/th√°ng * 0.875 (hi·ªáu su·∫•t) = 140 gi·ªù"
)

calculate_button = st.sidebar.button("üöÄ ∆Ø·ªõc t√≠nh & So s√°nh", use_container_width=True, type="primary")

if calculate_button:
    st.divider()
    st.subheader("üìä K·∫øt qu·∫£ ∆Ø·ªõc t√≠nh T·ªïng h·ª£p")

    loc_to_use, fp_to_use, ucp_to_use = 0.0, 0.0, 0.0
    conversion_errors = []

    try:
        if loc_per_fp_factor_to_use <= 0: conversion_errors.append("H·ªá s·ªë LOC/FP ph·∫£i > 0.")
        if fp_per_ucp_factor <= 0: conversion_errors.append("H·ªá s·ªë FP/UCP ph·∫£i > 0.")

        if not conversion_errors:
            if primary_metric_type == "LOC":
                loc_to_use = float(primary_metric_val)
                fp_to_use = loc_to_use / loc_per_fp_factor_to_use if loc_per_fp_factor_to_use > 0 else 0.0
                ucp_to_use = fp_to_use / fp_per_ucp_factor if fp_per_ucp_factor > 0 else 0.0
            elif primary_metric_type == "FP":
                fp_to_use = float(primary_metric_val)
                loc_to_use = fp_to_use * loc_per_fp_factor_to_use
                ucp_to_use = fp_to_use / fp_per_ucp_factor if fp_per_ucp_factor > 0 else 0.0
            else:  # UCP
                ucp_to_use = float(primary_metric_val)
                fp_to_use = ucp_to_use * fp_per_ucp_factor
                loc_to_use = fp_to_use * loc_per_fp_factor_to_use

        loc_to_use_display = round(loc_to_use)
        fp_to_use_display = round(fp_to_use, 2)
        ucp_to_use_display = round(ucp_to_use, 2)

    except Exception as e_conv:
        conversion_errors.append(f"L·ªói trong qu√° tr√¨nh chuy·ªÉn ƒë·ªïi ch·ªâ s·ªë: {e_conv}")

    if conversion_errors:
        for err in conversion_errors: st.error(f"L·ªói h·ªá s·ªë chuy·ªÉn ƒë·ªïi: {err}")
        st.stop()

    st.markdown("#### Gi√° tr·ªã k√≠ch th∆∞·ªõc ƒë∆∞·ª£c s·ª≠ d·ª•ng cho t√≠nh to√°n:")
    col_size1, col_size2, col_size3 = st.columns(3)
    col_size1.metric("Lines of Code (LOC)", f"{loc_to_use_display:,.0f}")
    col_size2.metric("Function Points (FP)", f"{fp_to_use_display:,.2f}")
    col_size3.metric("Use Case Points (UCP)", f"{ucp_to_use_display:,.2f}")
    st.caption(
        f"(ƒê·∫ßu v√†o ch√≠nh: {primary_metric_type}. Ng√¥n ng·ªØ/Lo·∫°i cho LOC/FP: {selected_language_profile} -> {loc_per_fp_factor_to_use} LOC/FP.)")
    st.markdown("---")

    all_results_list = []
    error_messages_ml = {}

    # --- 1. D·ª± ƒëo√°n t·ª´ M√¥ h√¨nh Machine Learning ---
    if preprocessor and feature_names_out and ml_models and original_cols_order and categorical_features_options:
        st.markdown("##### 1. D·ª± ƒëo√°n t·ª´ M√¥ h√¨nh Machine Learning")
        try:
            current_input_data_ml = input_values_ml_extra.copy()
            if 'LOC' in original_cols_order: current_input_data_ml['LOC'] = loc_to_use
            if 'FP' in original_cols_order: current_input_data_ml['FP'] = fp_to_use
            if 'UCP' in original_cols_order: current_input_data_ml['UCP'] = ucp_to_use
            # N·∫øu ML model ƒë∆∞·ª£c hu·∫•n luy·ªán v·ªõi feature 'Language Profile' ho·∫∑c t∆∞∆°ng t·ª±,
            # b·∫°n c·∫ßn th√™m selected_language_profile v√†o current_input_data_ml ·ªü ƒë√¢y.
            # V√≠ d·ª•: if 'Language_Profile_Feature_Name_In_Model' in original_cols_order:
            # current_input_data_ml['Language_Profile_Feature_Name_In_Model'] = selected_language_profile

            ordered_input_data_for_ml_df = {}
            missing_inputs_ml = []
            for col in original_cols_order:
                if col in current_input_data_ml:
                    ordered_input_data_for_ml_df[col] = current_input_data_ml[col]
                else:
                    missing_inputs_ml.append(col)
                    ordered_input_data_for_ml_df[col] = np.nan

            if missing_inputs_ml:
                st.warning(f"ML Input: Thi·∫øu gi√° tr·ªã cho: {', '.join(missing_inputs_ml)}. S·∫Ω ƒë∆∞·ª£c Imputer x·ª≠ l√Ω.")

            input_df_ml = pd.DataFrame([ordered_input_data_for_ml_df], columns=original_cols_order)
            input_processed_np = preprocessor.transform(input_df_ml)

            if isinstance(feature_names_out, list) and len(feature_names_out) == input_processed_np.shape[1]:
                input_processed_df = pd.DataFrame(input_processed_np, columns=feature_names_out)
                for model_name, loaded_model in ml_models.items():
                    effort_ph, dev_time_m, team_size_p = "L·ªói", "N/A", "N/A"
                    try:
                        pred = loaded_model.predict(input_processed_df)
                        effort_ph = max(0.0, round(float(pred[0]) if pred.size > 0 else 0.0, 2))
                        if isinstance(effort_ph, float) and effective_hours_per_month_sched > 0:
                            effort_pm_sched = effort_ph / effective_hours_per_month_sched
                            if scheduling_basis == "Quy m√¥ ƒë·ªôi ng≈© ƒë√£ bi·∫øt" and team_size_input_sched and team_size_input_sched > 0:
                                dev_time_m = round(effort_pm_sched / team_size_input_sched, 1)
                                team_size_p = team_size_input_sched
                            elif scheduling_basis == "Th·ªùi gian ph√°t tri·ªÉn mong mu·ªën" and dev_time_input_sched and dev_time_input_sched > 0:
                                team_size_p = math.ceil(effort_pm_sched / dev_time_input_sched)
                                dev_time_m = dev_time_input_sched
                    except Exception as model_pred_e:
                        error_messages_ml[model_name] = str(model_pred_e)
                    all_results_list.append({
                        'LOC': loc_to_use_display, 'UCP': ucp_to_use_display, 'FP': fp_to_use_display,
                        'M√¥ H√¨nh': f"ML: {model_name}", 'Effort (gi·ªù)': effort_ph,
                        'Th·ªùi Gian (Th√°ng)': dev_time_m, 'ƒê·ªôi Ng≈© (Ng∆∞·ªùi)': team_size_p
                    })
            else:
                st.error(f"L·ªói ML: S·ªë ƒë·∫∑c tr∆∞ng ({len(feature_names_out)}) kh√¥ng kh·ªõp ({input_processed_np.shape[1]}).")
                for model_name in ml_models.keys():
                    all_results_list.append(
                        {'LOC': loc_to_use_display, 'UCP': ucp_to_use_display, 'FP': fp_to_use_display,
                         'M√¥ H√¨nh': f"ML: {model_name}", 'Effort (gi·ªù)': "L·ªói (Config)", 'Th·ªùi Gian (Th√°ng)': "N/A",
                         'ƒê·ªôi Ng≈© (Ng∆∞·ªùi)': "N/A"})
        except Exception as e_ml_process:
            st.error(f"L·ªói x·ª≠ l√Ω/d·ª± ƒëo√°n ML: {e_ml_process}")
            for model_name in ml_models.keys():
                all_results_list.append({'LOC': loc_to_use_display, 'UCP': ucp_to_use_display, 'FP': fp_to_use_display,
                                         'M√¥ H√¨nh': f"ML: {model_name}", 'Effort (gi·ªù)': "L·ªói (Process)",
                                         'Th·ªùi Gian (Th√°ng)': "N/A", 'ƒê·ªôi Ng≈© (Ng∆∞·ªùi)': "N/A"})
            print(traceback.format_exc())
    else:
        st.info("D·ª± ƒëo√°n ML kh√¥ng th·ª±c hi·ªán do thi·∫øu th√†nh ph·∫ßn / kh√¥ng c√≥ model ML.")

    # --- 2. T√≠nh to√°n t·ª´ M√¥ h√¨nh Truy·ªÅn th·ªëng ---
    st.markdown("##### 2. T√≠nh to√°n t·ª´ M√¥ h√¨nh Truy·ªÅn th·ªëng")
    traditional_models_params_display = []

    effort_cocomo = calculate_cocomo_basic(loc_to_use, cocomo_mode, eaf, hours_per_month_cocomo)
    dt_cocomo, ts_cocomo = "N/A", "N/A"
    if isinstance(effort_cocomo, float) and effective_hours_per_month_sched > 0:
        effort_pm_sched_cocomo = effort_cocomo / effective_hours_per_month_sched
        if scheduling_basis == "Quy m√¥ ƒë·ªôi ng≈© ƒë√£ bi·∫øt" and team_size_input_sched and team_size_input_sched > 0:
            dt_cocomo = round(effort_pm_sched_cocomo / team_size_input_sched, 1);
            ts_cocomo = team_size_input_sched
        elif scheduling_basis == "Th·ªùi gian ph√°t tri·ªÉn mong mu·ªën" and dev_time_input_sched and dev_time_input_sched > 0:
            ts_cocomo = math.ceil(effort_pm_sched_cocomo / dev_time_input_sched);
            dt_cocomo = dev_time_input_sched
    all_results_list.append(
        {'LOC': loc_to_use_display, 'UCP': ucp_to_use_display, 'FP': fp_to_use_display, 'M√¥ H√¨nh': 'COCOMO II (Basic)',
         'Effort (gi·ªù)': effort_cocomo, 'Th·ªùi Gian (Th√°ng)': dt_cocomo, 'ƒê·ªôi Ng≈© (Ng∆∞·ªùi)': ts_cocomo})
    traditional_models_params_display.append(
        f"* **COCOMO II:** Mode={cocomo_mode}, EAF={eaf}, Hrs/Month (COCOMO)={hours_per_month_cocomo}")

    effort_fp = calculate_fp_effort(fp_to_use)
    dt_fp, ts_fp = "N/A", "N/A"
    if isinstance(effort_fp, float) and effective_hours_per_month_sched > 0:
        effort_pm_sched_fp = effort_fp / effective_hours_per_month_sched
        if scheduling_basis == "Quy m√¥ ƒë·ªôi ng≈© ƒë√£ bi·∫øt" and team_size_input_sched and team_size_input_sched > 0:
            dt_fp = round(effort_pm_sched_fp / team_size_input_sched, 1);
            ts_fp = team_size_input_sched
        elif scheduling_basis == "Th·ªùi gian ph√°t tri·ªÉn mong mu·ªën" and dev_time_input_sched and dev_time_input_sched > 0:
            ts_fp = math.ceil(effort_pm_sched_fp / dev_time_input_sched);
            dt_fp = dev_time_input_sched
    all_results_list.append(
        {'LOC': loc_to_use_display, 'UCP': ucp_to_use_display, 'FP': fp_to_use_display, 'M√¥ H√¨nh': 'Function Points',
         'Effort (gi·ªù)': effort_fp, 'Th·ªùi Gian (Th√°ng)': dt_fp, 'ƒê·ªôi Ng≈© (Ng∆∞·ªùi)': ts_fp})
    traditional_models_params_display.append(f"* **Function Points:** NƒÉng su·∫•t m·∫∑c ƒë·ªãnh={HOURS_PER_FP_DEFAULT} gi·ªù/FP")

    effort_ucp = calculate_ucp_effort(ucp_to_use)
    dt_ucp, ts_ucp = "N/A", "N/A"
    if isinstance(effort_ucp, float) and effective_hours_per_month_sched > 0:
        effort_pm_sched_ucp = effort_ucp / effective_hours_per_month_sched
        if scheduling_basis == "Quy m√¥ ƒë·ªôi ng≈© ƒë√£ bi·∫øt" and team_size_input_sched and team_size_input_sched > 0:
            dt_ucp = round(effort_pm_sched_ucp / team_size_input_sched, 1);
            ts_ucp = team_size_input_sched
        elif scheduling_basis == "Th·ªùi gian ph√°t tri·ªÉn mong mu·ªën" and dev_time_input_sched and dev_time_input_sched > 0:
            ts_ucp = math.ceil(effort_pm_sched_ucp / dev_time_input_sched);
            dt_ucp = dev_time_input_sched
    all_results_list.append(
        {'LOC': loc_to_use_display, 'UCP': ucp_to_use_display, 'FP': fp_to_use_display, 'M√¥ H√¨nh': 'Use Case Points',
         'Effort (gi·ªù)': effort_ucp, 'Th·ªùi Gian (Th√°ng)': dt_ucp, 'ƒê·ªôi Ng≈© (Ng∆∞·ªùi)': ts_ucp})
    traditional_models_params_display.append(
        f"* **Use Case Points:** NƒÉng su·∫•t m·∫∑c ƒë·ªãnh={HOURS_PER_UCP_DEFAULT} gi·ªù/UCP")

    st.markdown("**Tham s·ªë m√¥ h√¨nh truy·ªÅn th·ªëng (ngo√†i LOC/FP/UCP):**")
    for caption in traditional_models_params_display: st.markdown(caption)
    st.markdown("**Tham s·ªë l·∫≠p k·∫ø ho·∫°ch chung:**")
    st.markdown(f"* T√≠nh to√°n d·ª±a tr√™n: **{scheduling_basis}**")
    if scheduling_basis == "Quy m√¥ ƒë·ªôi ng≈© ƒë√£ bi·∫øt":
        st.markdown(f"* Quy m√¥ ƒë·ªôi cung c·∫•p: **{team_size_input_sched or 'N/A'} ng∆∞·ªùi**")
    else:
        st.markdown(f"* Th·ªùi gian ph√°t tri·ªÉn mong mu·ªën: **{dev_time_input_sched or 'N/A'} th√°ng**")
    st.markdown(f"* S·ªë gi·ªù hi·ªáu qu·∫£/ng∆∞·ªùi/th√°ng: **{effective_hours_per_month_sched} gi·ªù**")
    st.caption("L∆∞u √Ω: 'L·ªói' n·∫øu ƒë·∫ßu v√†o kh√¥ng h·ª£p l·ªá. 'N/A' n·∫øu kh√¥ng th·ªÉ t√≠nh th·ªùi gian/ƒë·ªôi ng≈©.")
    st.markdown("---")

    st.markdown("##### 3. B·∫£ng v√† Bi·ªÉu ƒë·ªì So s√°nh")
    if all_results_list:
        result_df = pd.DataFrame(all_results_list)
        cols_ordered = ['LOC', 'UCP', 'FP', 'M√¥ H√¨nh', 'Effort (gi·ªù)', 'Th·ªùi Gian (Th√°ng)', 'ƒê·ªôi Ng≈© (Ng∆∞·ªùi)']
        result_df = result_df[cols_ordered]


        def format_value_display(value, is_effort_or_loc=False, is_fp_ucp=False):
            if isinstance(value, (int, float)):
                if np.isnan(value): return "N/A"
                if is_effort_or_loc:
                    return f"{value:,.0f}" if value % 1 == 0 else f"{value:,.2f}"
                elif is_fp_ucp:
                    return f"{value:,.2f}"
                else:
                    return f"{value:,.1f}" if value % 1 != 0 else f"{value:,.0f}"
            return str(value)


        st.write("B·∫£ng so s√°nh k·∫øt qu·∫£:")
        display_df = result_df.copy()
        display_df['LOC'] = display_df['LOC'].apply(lambda x: format_value_display(x, is_effort_or_loc=True))
        display_df['UCP'] = display_df['UCP'].apply(lambda x: format_value_display(x, is_fp_ucp=True))
        display_df['FP'] = display_df['FP'].apply(lambda x: format_value_display(x, is_fp_ucp=True))
        display_df['Effort (gi·ªù)'] = display_df['Effort (gi·ªù)'].apply(
            lambda x: format_value_display(x, is_effort_or_loc=True))
        display_df['Th·ªùi Gian (Th√°ng)'] = display_df['Th·ªùi Gian (Th√°ng)'].apply(format_value_display)
        display_df['ƒê·ªôi Ng≈© (Ng∆∞·ªùi)'] = display_df['ƒê·ªôi Ng≈© (Ng∆∞·ªùi)'].apply(format_value_display)
        st.dataframe(display_df, use_container_width=True, hide_index=True)

        st.write("Bi·ªÉu ƒë·ªì so s√°nh Effort (gi·ªù):")
        try:
            chart_df_effort = result_df.copy()
            chart_df_effort['Effort (gi·ªù)'] = pd.to_numeric(chart_df_effort['Effort (gi·ªù)'], errors='coerce')
            chart_df_effort.dropna(subset=['Effort (gi·ªù)'], inplace=True)
            if not chart_df_effort.empty:
                st.bar_chart(chart_df_effort.set_index('M√¥ H√¨nh')['Effort (gi·ªù)'])
            else:
                st.info("Kh√¥ng c√≥ d·ªØ li·ªáu Effort h·ª£p l·ªá ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì.")
        except Exception as chart_e:
            st.warning(f"Kh√¥ng th·ªÉ v·∫Ω bi·ªÉu ƒë·ªì Effort: {chart_e}"); print(traceback.format_exc())
    else:
        st.warning("Kh√¥ng c√≥ k·∫øt qu·∫£ n√†o ƒë·ªÉ hi·ªÉn th·ªã.")

    if error_messages_ml:
        st.subheader("‚ö†Ô∏è Chi ti·∫øt l·ªói d·ª± ƒëo√°n ML:")
        for model_name, msg in error_messages_ml.items(): st.caption(f"**{model_name}:** {msg}")
    st.info("""**L∆∞u √Ω quan tr·ªçng:** K·∫øt qu·∫£ ch·ªâ l√† **∆∞·ªõc t√≠nh**. ƒê·ªô ch√≠nh x√°c ph·ª• thu·ªôc v√†o nhi·ªÅu y·∫øu t·ªë.""")

elif not ml_models and not preprocessor and not os.path.exists(PREPROCESSOR_PATH):
    st.error("L·ªói t·∫£i th√†nh ph·∫ßn ML (preprocessor, models). Ki·ªÉm tra ƒë∆∞·ªùng d·∫´n.")
elif not ml_models and (preprocessor or os.path.exists(PREPROCESSOR_PATH)):
    st.warning("Kh√¥ng t·∫£i ƒë∆∞·ª£c model ML. Ph·∫ßn ML s·∫Ω kh√¥ng ho·∫°t ƒë·ªông.")
elif not preprocessor or not feature_names_out or not original_cols_order or not categorical_features_options:
    st.error("L·ªói t·∫£i/x·ª≠ l√Ω preprocessor/th√¥ng tin ƒë·∫∑c tr∆∞ng ML.")

st.markdown("---")
st.caption(
    f"Demo App. NƒÉng su·∫•t FP m·∫∑c ƒë·ªãnh: {HOURS_PER_FP_DEFAULT} gi·ªù/FP. NƒÉng su·∫•t UCP m·∫∑c ƒë·ªãnh: {HOURS_PER_UCP_DEFAULT} gi·ªù/UCP.")