# Import c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt
import streamlit as st
import pandas as pd
import numpy as np
import joblib  # ƒê·ªÉ t·∫£i m√¥ h√¨nh v√† preprocessors
import matplotlib.pyplot as plt  # Th√™m th∆∞ vi·ªán matplotlib

# --- H·∫±ng s·ªë v√† D·ªØ li·ªáu M√¥ ph·ªèng ---
COCOMO_A = 2.4
COCOMO_B = 1.05
COCOMO_C = 2.5
COCOMO_D = 0.38
EFFORT_PER_UCP = 20
HOURS_PER_PERSON_MONTH = 152  # S·ªë gi·ªù l√†m vi·ªác trung b√¨nh m·ªói th√°ng cho m·ªôt ng∆∞·ªùi

# D·ªØ li·ªáu n√†y v·∫´n c·∫ßn thi·∫øt cho vi·ªác t√≠nh to√°n s∆° b·ªô v√† quy ƒë·ªïi LOC/FP
AVG_LOC_PER_FP = {
    'Java': 53, 'Python': 35, 'C++': 47, 'C#': 54, 'JavaScript': 47,
    'SQL': 15, 'COBOL': 90, 'ABAP': 70, 'PHP': 40, 'Swift': 30,
    'Kotlin': 32, 'Ruby': 25, 'Go': 45, 'Assembly': 200,
    'Scripting': 20, 'Visual Basic': 32, 'Ada': 71, 'Perl': 27,
    'Kh√°c': 50  # Gi√° tr·ªã m·∫∑c ƒë·ªãnh/trung b√¨nh
}

# --- C·∫≠p nh·∫≠t c√°c l·ª±a ch·ªçn cho Selectbox d·ª±a tr√™n c·ªôt m·ªõi ---
# C√°c gi√° tr·ªã n√†y b·∫°n n√™n c·∫≠p nh·∫≠t t·ª´ d·ªØ li·ªáu th·ª±c t·∫ø c·ªßa m√¨nh
PROJECT_TYPES_OPTIONS = ['Ph√°t tri·ªÉn m·ªõi', 'N√¢ng c·∫•p l·ªõn', 'B·∫£o tr√¨', 'T√°i c·∫•u tr√∫c', 'T√≠ch h·ª£p h·ªá th·ªëng',
                         'Kh√°c']  # Gi·ªØ nguy√™n ho·∫∑c c·∫≠p nh·∫≠t
LANGUAGE_TYPES_OPTIONS = ['3GL', '4GL', 'Assembly', 'Scripting', 'Ng√¥n ng·ªØ truy v·∫•n (SQL)',
                          'Ng√¥n ng·ªØ ƒë√°nh d·∫•u (HTML/XML)', 'Kh√°c']  # Gi·ªØ nguy√™n ho·∫∑c c·∫≠p nh·∫≠t
PRIMARY_PROGRAMMING_LANGUAGES_OPTIONS = sorted(
    list(AVG_LOC_PER_FP.keys()))  # L·∫•y t·ª´ AVG_LOC_PER_FP ho·∫∑c danh s√°ch th·ª±c t·∫ø
COUNT_APPROACH_OPTIONS = ['IFPUG', 'NESMA', 'FiSMA', 'COSMIC', 'Mark II', 'LOC Manual', 'Kh√°c']  # V√≠ d·ª•
APPLICATION_GROUP_OPTIONS = ['Nghi·ªáp v·ª• (Business)', 'H·ªó tr·ª£ Quy·∫øt ƒë·ªãnh (Decision Support)',
                             'Khoa h·ªçc/K·ªπ thu·∫≠t (Scientific/Engineering)', 'Th·ªùi gian th·ª±c (Real-time)',
                             'H·ªá th·ªëng (System Software)', 'Ti·ªán √≠ch (Utility)', 'Kh√°c']  # V√≠ d·ª•
APPLICATION_TYPES_OPTIONS = ['·ª®ng d·ª•ng Web', '·ª®ng d·ª•ng Di ƒë·ªông', '·ª®ng d·ª•ng Desktop', 'H·ªá th·ªëng Nh√∫ng',
                             'X·ª≠ l√Ω D·ªØ li·ªáu/Batch', 'API/D·ªãch v·ª•', 'Tr√≠ tu·ªá nh√¢n t·∫°o/ML', 'Game',
                             'Kh√°c']  # Gi·ªØ nguy√™n ho·∫∑c c·∫≠p nh·∫≠t
DEVELOPMENT_TYPES_OPTIONS = ['N·ªôi b·ªô (In-house)', 'Thu√™ ngo√†i (Outsource)', 'H·ªón h·ª£p (Hybrid)',
                             'M√£ ngu·ªìn m·ªü (ƒê√≥ng g√≥p)', 'S·∫£n ph·∫©m (COTS) t√πy ch·ªânh', 'Kh√°c']  # Gi·ªØ nguy√™n ho·∫∑c c·∫≠p nh·∫≠t

# --- ƒê·ªãnh nghƒ©a c√°c c·ªôt (quan tr·ªçng cho ti·ªÅn x·ª≠ l√Ω) ---
# C·ªôt m·ª•c ti√™u (target variable) th∆∞·ªùng l√† 'Effort (person-hours)' v√† kh√¥ng n·∫±m trong features
NUMERICAL_FEATURES_RAW = ['LOC', 'FP', 'UCP', 'Development Time (months)', 'Team Size']

CATEGORICAL_FEATURES_RAW = [
    'Project Type',
    'Language Type',
    'Primary Programming Language',
    'Count Approach',
    'Application Group',
    'Application Type',
    'Development Type'
]

# ----- !!! QUAN TR·ªåNG: C·∫¨P NH·∫¨T X_TRAIN_COLUMNS_ORDERED !!! -----
# Danh s√°ch n√†y PH·∫¢I KH·ªöP CH√çNH X√ÅC v·ªõi t√™n v√† th·ª© t·ª± c√°c c·ªôt
# m√† m√¥ h√¨nh c·ªßa b·∫°n ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán (SAU KHI One-Hot Encoding v√† Scaling).
# D∆∞·ªõi ƒë√¢y l√† m·ªôt V√ç D·ª§ d·ª±a tr√™n c√°c t√πy ch·ªçn ·ªü tr√™n.
# B·∫†N C·∫¶N THAY TH·∫æ B·∫∞NG C√ÅC T√äN C·ªòT ONE-HOT ENCODED TH·ª∞C T·∫æ T·ª™ D·ªÆ LI·ªÜU C·ª¶A B·∫†N.
X_TRAIN_COLUMNS_ORDERED = NUMERICAL_FEATURES_RAW + \
                          [f'Project Type_{val}' for val in PROJECT_TYPES_OPTIONS] + \
                          [f'Language Type_{val}' for val in LANGUAGE_TYPES_OPTIONS] + \
                          [f'Primary Programming Language_{val}' for val in PRIMARY_PROGRAMMING_LANGUAGES_OPTIONS] + \
                          [f'Count Approach_{val}' for val in COUNT_APPROACH_OPTIONS] + \
                          [f'Application Group_{val}' for val in APPLICATION_GROUP_OPTIONS] + \
                          [f'Application Type_{val}' for val in APPLICATION_TYPES_OPTIONS] + \
                          [f'Development Type_{val}' for val in DEVELOPMENT_TYPES_OPTIONS]


# Lo·∫°i b·ªè c√°c c·ªôt c√≥ th·ªÉ kh√¥ng ƒë∆∞·ª£c t·∫°o ra n·∫øu gi√° tr·ªã kh√¥ng c√≥ trong d·ªØ li·ªáu hu·∫•n luy·ªán
# V√≠ d·ª•: n·∫øu 'Project Type_Kh√°c' kh√¥ng c√≥ trong d·ªØ li·ªáu hu·∫•n luy·ªán, n√≥ s·∫Ω kh√¥ng ƒë∆∞·ª£c t·∫°o ra b·ªüi encoder.
# C√°ch t·ªët nh·∫•t l√† l·∫•y danh s√°ch c·ªôt n√†y t·ª´ `encoder.get_feature_names_out()` ho·∫∑c t·ª´ `X_train.columns` sau khi x·ª≠ l√Ω.


# --- H√†m T√≠nh To√°n (ƒë√£ c√≥ t·ª´ tr∆∞·ªõc) ---
def calculate_metrics(size_metric_choice, size_metric_value, language):
    calculated_loc = 0.0
    calculated_fp = 0.0
    calculated_ucp = 0.0
    estimated_effort_pm = 0.0  # Person-Months
    estimated_dev_time_months = 0.0
    estimated_team_size = 0.0
    loc_fp_ratio = AVG_LOC_PER_FP.get(language, AVG_LOC_PER_FP['Kh√°c'])

    if size_metric_value <= 0:
        return calculated_loc, calculated_fp, calculated_ucp, estimated_effort_pm, estimated_dev_time_months, estimated_team_size

    if size_metric_choice == 'LOC':
        calculated_loc = size_metric_value
        if loc_fp_ratio > 0: calculated_fp = calculated_loc / loc_fp_ratio
        kloc = calculated_loc / 1000
        if kloc > 0:
            effort_pm_from_loc = COCOMO_A * (kloc ** COCOMO_B)
            if EFFORT_PER_UCP > 0 and HOURS_PER_PERSON_MONTH > 0:
                calculated_ucp = (effort_pm_from_loc * HOURS_PER_PERSON_MONTH) / EFFORT_PER_UCP
    elif size_metric_choice == 'FP':
        calculated_fp = size_metric_value
        calculated_loc = calculated_fp * loc_fp_ratio
        kloc = calculated_loc / 1000
        if kloc > 0:
            effort_pm_from_fp_via_loc = COCOMO_A * (kloc ** COCOMO_B)
            if EFFORT_PER_UCP > 0 and HOURS_PER_PERSON_MONTH > 0:
                calculated_ucp = (effort_pm_from_fp_via_loc * HOURS_PER_PERSON_MONTH) / EFFORT_PER_UCP
    elif size_metric_choice == 'UCP':
        calculated_ucp = size_metric_value
        if EFFORT_PER_UCP > 0 and HOURS_PER_PERSON_MONTH > 0:
            effort_pm_from_ucp = (calculated_ucp * EFFORT_PER_UCP) / HOURS_PER_PERSON_MONTH
            if COCOMO_A > 0 and COCOMO_B != 0 and effort_pm_from_ucp > 0:
                base_cocomo = effort_pm_from_ucp / COCOMO_A
                if base_cocomo > 0:
                    kloc = base_cocomo ** (1 / COCOMO_B)
                    calculated_loc = kloc * 1000
                    if loc_fp_ratio > 0: calculated_fp = calculated_loc / loc_fp_ratio

    final_kloc = calculated_loc / 1000
    if final_kloc > 0:
        estimated_effort_pm = COCOMO_A * (final_kloc ** COCOMO_B)  # Effort n√†y l√† Person-Months
        if estimated_effort_pm > 0:
            base_dev_time = estimated_effort_pm
            if base_dev_time > 0:
                estimated_dev_time_months = COCOMO_C * (base_dev_time ** COCOMO_D)
            if estimated_dev_time_months > 0:
                estimated_team_size = estimated_effort_pm / estimated_dev_time_months
            else:
                estimated_team_size = 1 if estimated_effort_pm > 0 else 0

    return (
        round(calculated_loc, 2), round(calculated_fp, 2), round(calculated_ucp, 2),
        round(estimated_effort_pm, 2), round(estimated_dev_time_months, 2), round(estimated_team_size, 2)
    )


# --- H√†m COCOMO II ---
def estimate_cocomo_effort(kloc, project_type_cocomo="Organic", cost_drivers=None):
    effort_multipliers = 1.0
    if cost_drivers:
        for driver_value in cost_drivers.values():
            effort_multipliers *= driver_value

    cocomo_params = {
        "Organic": (2.4, 1.05),
        "Semi-detached": (3.0, 1.12),
        "Embedded": (3.6, 1.20)
    }
    a, b = cocomo_params.get(project_type_cocomo, cocomo_params["Organic"])

    if kloc <= 0: return 0.0
    effort_pm = a * (kloc ** b) * effort_multipliers  # Effort n√†y l√† Person-Months
    return round(effort_pm, 2)


# --- H√†m t·∫£i m√¥ h√¨nh v√† preprocessors ---
def load_model_and_preprocessors():
    models = {}
    scaler = None
    # Gi·∫£ s·ª≠ b·∫°n l∆∞u t·ª´ng encoder ri√™ng l·∫ª ho·∫∑c m·ªôt ColumnTransformer
    encoders = {}  # V√≠ d·ª•: {'Project Type': loaded_encoder_for_project_type, ...}
    # HO·∫∂C column_transformer = joblib.load('column_transformer.pkl')

    model_files = {
        'Linear Regression': 'linear_regression_model.pkl',
        'Decision Tree': 'decision_tree_model.pkl',
        'Random Forest': 'random_forest_model.pkl',
        'XGBoost': 'xgb_regressor_model.pkl',
        'MLP Regressor': 'mlp_regressor_model.pkl'
    }

    try:
        # scaler = joblib.load('scaler.pkl') # B·ªè comment v√† s·ª≠a ƒë∆∞·ªùng d·∫´n file
        st.sidebar.warning("Scaler (scaler.pkl) ch∆∞a ƒë∆∞·ª£c t·∫£i. S·ª≠ d·ª•ng d·ªØ li·ªáu ch∆∞a scale.")

        # V√≠ d·ª• t·∫£i t·ª´ng encoder (C·∫¶N ƒêI·ªÄU CH·ªàNH THEO C√ÅCH B·∫†N L∆ØU ENCODERS):
        # for col in CATEGORICAL_FEATURES_RAW:
        #     try:
        #         # T√™n file encoder c√≥ th·ªÉ kh√°c nhau t√πy theo c√°ch b·∫°n l∆∞u
        #         encoders[col] = joblib.load(f'{col.lower().replace(" ", "_").replace("/", "_")}_encoder.pkl')
        #     except FileNotFoundError:
        #         st.sidebar.warning(f"Encoder cho c·ªôt '{col}' kh√¥ng t√¨m th·∫•y. M√£ h√≥a one-hot c√≥ th·ªÉ kh√¥ng ch√≠nh x√°c.")
        #         encoders[col] = None # Quan tr·ªçng: ƒë√°nh d·∫•u l√† None n·∫øu kh√¥ng t·∫£i ƒë∆∞·ª£c
        st.sidebar.warning(
            "C√°c encoders ch∆∞a ƒë∆∞·ª£c t·∫£i. M√£ h√≥a one-hot s·∫Ω kh√¥ng ch√≠nh x√°c. C·∫ßn cung c·∫•p c√°c file .pkl cho encoders.")

        for model_name, file_name in model_files.items():
            # models[model_name] = joblib.load(file_name) # B·ªè comment v√† s·ª≠a ƒë∆∞·ªùng d·∫´n file
            st.sidebar.warning(f"M√¥ h√¨nh {model_name} ({file_name}) ch∆∞a ƒë∆∞·ª£c t·∫£i. S·∫Ω kh√¥ng c√≥ d·ª± ƒëo√°n t·ª´ m√¥ h√¨nh n√†y.")
            models[model_name] = None  # Placeholder n·∫øu kh√¥ng t·∫£i ƒë∆∞·ª£c

    except FileNotFoundError as e:
        st.sidebar.error(f"L·ªói: Kh√¥ng t√¨m th·∫•y file m√¥ h√¨nh ho·∫∑c preprocessor. Vui l√≤ng ki·ªÉm tra ƒë∆∞·ªùng d·∫´n. {e}")
    except Exception as e:
        st.sidebar.error(f"L·ªói khi t·∫£i m√¥ h√¨nh ho·∫∑c preprocessor: {e}")

    return models, scaler, encoders


# --- Giao di·ªán Streamlit ---
st.set_page_config(layout="wide")
st.title("‚öôÔ∏è C√¥ng c·ª• ∆Ø·ªõc t√≠nh N·ªó l·ª±c Ph√°t tri·ªÉn Ph·∫ßn m·ªÅm v3 (C·ªôt Th·ª±c T·∫ø)")

# Kh·ªüi t·∫°o session state
if 'ml_predictions_ph' not in st.session_state: st.session_state.ml_predictions_ph = None  # L∆∞u d·ª± ƒëo√°n ML (Person-Hours)
if 'cocomo_estimate_ph' not in st.session_state: st.session_state.cocomo_estimate_ph = None
if 'processed_input_df_display' not in st.session_state: st.session_state.processed_input_df_display = None
if 'raw_input_df_display' not in st.session_state: st.session_state.raw_input_df_display = None

# --- Sidebar ---
with st.sidebar:
    st.header("üìä Nh·∫≠p Th√¥ng tin & ∆Ø·ªõc t√≠nh")
    st.markdown("---")

    # C√°c tr∆∞·ªùng nh·∫≠p li·ªáu c∆° b·∫£n cho t√≠nh to√°n s∆° b·ªô
    size_metric_choice = st.selectbox(
        "Ch·ªçn ch·ªâ s·ªë k√≠ch th∆∞·ªõc ƒë·∫ßu v√†o ch√≠nh:", ('LOC', 'FP', 'UCP'), key='size_metric_choice_v3'
    )

    size_metric_label = f"Nh·∫≠p gi√° tr·ªã cho {size_metric_choice}:"
    if size_metric_choice == 'LOC':
        default_val_size, step_val_size = 10000.0, 1000.0
    elif size_metric_choice == 'FP':
        default_val_size, step_val_size = 200.0, 10.0
    else:
        default_val_size, step_val_size = 100.0, 5.0

    size_metric_value = st.number_input(
        size_metric_label, min_value=0.0, value=default_val_size, step=step_val_size, key='size_metric_value_v3',
        format="%.2f"
    )

    # Ng√¥n ng·ªØ l·∫≠p tr√¨nh ch√≠nh (v·∫´n c·∫ßn cho t√≠nh to√°n LOC/FP)
    selected_primary_programming_language = st.selectbox(
        "Ng√¥n ng·ªØ l·∫≠p tr√¨nh ch√≠nh (cho quy ƒë·ªïi LOC/FP):", PRIMARY_PROGRAMMING_LANGUAGES_OPTIONS,
        index=PRIMARY_PROGRAMMING_LANGUAGES_OPTIONS.index(
            'Java') if 'Java' in PRIMARY_PROGRAMMING_LANGUAGES_OPTIONS else 0,
        key='selected_primary_programming_language_v3'
    )

    # T√≠nh to√°n c√°c ch·ªâ s·ªë c∆° b·∫£n
    (calculated_loc, calculated_fp, calculated_ucp,
     estimated_effort_pm,  # ƒê√¢y l√† Person-Months t·ª´ COCOMO c∆° b·∫£n
     estimated_dev_time_months,
     estimated_team_size) = calculate_metrics(
        size_metric_choice, size_metric_value, selected_primary_programming_language
    )

    st.markdown("---")
    st.subheader("üìà C√°c Ch·ªâ s·ªë K√≠ch th∆∞·ªõc ∆Ø·ªõc t√≠nh:")
    col_loc_ucp, col_fp_empty = st.columns(2)
    with col_loc_ucp:
        st.metric(label="LOC", value=f"{calculated_loc:,.0f}",
                  delta="T√≠nh to√°n" if size_metric_choice != 'LOC' else "ƒê·∫ßu v√†o", delta_color="off")
        st.metric(label="UCP", value=f"{calculated_ucp:,.0f}",
                  delta="T√≠nh to√°n" if size_metric_choice != 'UCP' else "ƒê·∫ßu v√†o", delta_color="off")
    with col_fp_empty:
        st.metric(label="FP", value=f"{calculated_fp:,.0f}",
                  delta="T√≠nh to√°n" if size_metric_choice != 'FP' else "ƒê·∫ßu v√†o", delta_color="off")

    st.markdown("---")
    st.subheader("‚è±Ô∏è ∆Ø·ªõc t√≠nh S∆° b·ªô (COCOMO c∆° b·∫£n):")
    col_e_pm, col_t_m, col_s_p = st.columns(3)
    with col_e_pm:
        st.metric(label="N·ªó l·ª±c (Person-Months)", value=f"{estimated_effort_pm:,.1f}")  # Hi·ªÉn th·ªã PM
    with col_t_m:
        st.metric(label="T.Gian P.Tri·ªÉn (Th√°ng)", value=f"{estimated_dev_time_months:,.1f}")
    with col_s_p:
        st.metric(label="Quy m√¥ Nh√≥m (Ng∆∞·ªùi)", value=f"{estimated_team_size:,.1f}")

    st.markdown("---")
    st.subheader("üìã Th√¥ng tin Chi ti·∫øt D·ª± √°n (cho Model ML):")
    # C√°c tr∆∞·ªùng nh·∫≠p li·ªáu m·ªõi d·ª±a tr√™n c·ªôt th·ª±c t·∫ø
    # L∆∞u √Ω: c√°c gi√° tr·ªã LOC, FP, UCP, Dev Time, Team Size s·∫Ω l·∫•y t·ª´ calculated_* v√† estimated_* ·ªü tr√™n

    input_project_type = st.selectbox("Project Type:", PROJECT_TYPES_OPTIONS, key='input_project_type_v3')
    input_language_type = st.selectbox("Language Type:", LANGUAGE_TYPES_OPTIONS, key='input_language_type_v3')
    # Primary Programming Language cho model ML c√≥ th·ªÉ kh√°c v·ªõi c√°i d√πng ƒë·ªÉ quy ƒë·ªïi LOC/FP n·∫øu c·∫ßn
    input_primary_lang_model = st.selectbox("Primary Programming Language (cho Model ML):",
                                            PRIMARY_PROGRAMMING_LANGUAGES_OPTIONS,
                                            index=PRIMARY_PROGRAMMING_LANGUAGES_OPTIONS.index(
                                                selected_primary_programming_language) if selected_primary_programming_language in PRIMARY_PROGRAMMING_LANGUAGES_OPTIONS else 0,
                                            key='input_primary_lang_model_v3')
    input_count_approach = st.selectbox("Count Approach:", COUNT_APPROACH_OPTIONS, key='input_count_approach_v3')
    input_app_group = st.selectbox("Application Group:", APPLICATION_GROUP_OPTIONS, key='input_app_group_v3')
    input_app_type = st.selectbox("Application Type:", APPLICATION_TYPES_OPTIONS, key='input_app_type_v3')
    input_dev_type = st.selectbox("Development Type:", DEVELOPMENT_TYPES_OPTIONS, key='input_dev_type_v3')

    st.markdown("---")
    if st.button("üöÄ D·ª± ƒëo√°n Effort Ch√≠nh (ML & COCOMO II)", key='predict_effort_button_v3'):
        # 1. Thu th·∫≠p t·∫•t c·∫£ c√°c gi√° tr·ªã ƒë·∫ßu v√†o cho DataFrame
        input_data_for_df = {
            'LOC': calculated_loc,
            'FP': calculated_fp,
            'UCP': calculated_ucp,
            'Development Time (months)': estimated_dev_time_months,
            'Team Size': estimated_team_size,
            'Project Type': input_project_type,
            'Language Type': input_language_type,
            'Primary Programming Language': input_primary_lang_model,  # S·ª≠ d·ª•ng ng√¥n ng·ªØ ƒë√£ ch·ªçn cho model
            'Count Approach': input_count_approach,
            'Application Group': input_app_group,
            'Application Type': input_app_type,
            'Development Type': input_dev_type
        }
        input_df_raw = pd.DataFrame([input_data_for_df])
        st.session_state.raw_input_df_display = input_df_raw.copy()

        # 2. T·∫£i m√¥ h√¨nh v√† preprocessors
        models, scaler, encoders = load_model_and_preprocessors()

        # 3. Ti·ªÅn x·ª≠ l√Ω input DataFrame
        input_df_processed = input_df_raw.copy()
        processed_successfully = True

        # One-Hot Encoding
        if encoders:  # Ch·ªâ th·ª±c hi·ªán n·∫øu dict encoders c√≥ g√¨ ƒë√≥ (d√π l√† None)
            for col in CATEGORICAL_FEATURES_RAW:  # L·∫∑p qua c√°c c·ªôt c·∫ßn m√£ h√≥a
                if col in input_df_processed.columns:  # Ki·ªÉm tra c·ªôt c√≥ t·ªìn t·∫°i trong df kh√¥ng
                    encoder_for_col = encoders.get(col)  # L·∫•y encoder t∆∞∆°ng ·ª©ng
                    if encoder_for_col is not None:
                        try:
                            encoded_data = encoder_for_col.transform(input_df_processed[[col]])
                            encoded_cols = encoder_for_col.get_feature_names_out([col])
                            encoded_df = pd.DataFrame(encoded_data, index=input_df_processed.index,
                                                      columns=encoded_cols)
                            input_df_processed = pd.concat([input_df_processed.drop(col, axis=1), encoded_df], axis=1)
                        except Exception as e:
                            st.error(f"L·ªói khi √°p d·ª•ng OneHotEncoder ƒë√£ t·∫£i cho c·ªôt '{col}': {e}.")
                            processed_successfully = False;
                            break
                    # else: st.warning(f"Kh√¥ng c√≥ encoder ƒë√£ t·∫£i cho c·ªôt '{col}'. B·ªè qua m√£ h√≥a c·ªôt n√†y b·∫±ng encoder ƒë√£ l∆∞u.")
                # else: st.warning(f"C·ªôt '{col}' kh√¥ng c√≥ trong input_df_processed ƒë·ªÉ m√£ h√≥a.")

        # N·∫øu kh√¥ng c√≥ encoder ƒë√£ t·∫£i ho·∫∑c c√≥ l·ªói, th·ª≠ pd.get_dummies nh∆∞ m·ªôt fallback
        # ƒêi·ªÅu n√†y c·∫ßn X_TRAIN_COLUMNS_ORDERED ph·∫£i ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a r·∫•t c·∫©n th·∫≠n
        # ƒë·ªÉ kh·ªõp v·ªõi k·∫øt qu·∫£ c·ªßa pd.get_dummies tr√™n d·ªØ li·ªáu hu·∫•n luy·ªán.
        if not encoders or not processed_successfully:  # N·∫øu kh√¥ng c√≥ dict encoders ho·∫∑c ƒë√£ l·ªói
            st.warning(
                "Kh√¥ng c√≥ encoders ƒë∆∞·ª£c t·∫£i ƒë·∫ßy ƒë·ªß ho·∫∑c c√≥ l·ªói. S·ª≠ d·ª•ng pd.get_dummies() cho t·∫•t c·∫£ c√°c c·ªôt ph√¢n lo·∫°i. ƒê·∫£m b·∫£o X_TRAIN_COLUMNS_ORDERED kh·ªõp v·ªõi c√°ch n√†y.")
            try:
                input_df_processed = pd.get_dummies(input_df_processed, columns=CATEGORICAL_FEATURES_RAW,
                                                    dummy_na=False)
                processed_successfully = True  # Gi·∫£ s·ª≠ th√†nh c√¥ng n·∫øu kh√¥ng c√≥ l·ªói
            except Exception as e:
                st.error(f"L·ªói khi s·ª≠ d·ª•ng pd.get_dummies: {e}");
                processed_successfully = False

        # √Åp d·ª•ng Chu·∫©n h√≥a (StandardScaler)
        if scaler and processed_successfully:
            try:
                # Ch·ªâ scale c√°c c·ªôt s·ªë c√≥ trong input_df_processed v√† NUMERICAL_FEATURES_RAW
                cols_to_scale = [col for col in NUMERICAL_FEATURES_RAW if col in input_df_processed.columns]
                if cols_to_scale:
                    input_df_processed[cols_to_scale] = scaler.transform(input_df_processed[cols_to_scale])
                # else: st.warning("Kh√¥ng c√≥ c·ªôt s·ªë n√†o ƒë·ªÉ scale trong d·ªØ li·ªáu ƒë·∫ßu v√†o sau OHE.")
            except ValueError as ve:
                st.error(
                    f"L·ªói ValueError khi √°p d·ª•ng StandardScaler: {ve}. C√≥ th·ªÉ do s·ªë l∆∞·ª£ng features kh√¥ng kh·ªõp. Ki·ªÉm tra c√°c c·ªôt: {cols_to_scale}")
                processed_successfully = False
            except Exception as e:
                st.error(f"L·ªói khi √°p d·ª•ng StandardScaler: {e}.")
                processed_successfully = False
        # else:
        #     if not scaler: st.warning("Scaler ch∆∞a ƒë∆∞·ª£c t·∫£i. D·ªØ li·ªáu s·ªë s·∫Ω kh√¥ng ƒë∆∞·ª£c chu·∫©n h√≥a.")

        # ƒê·∫£m b·∫£o th·ª© t·ª± c√°c c·ªôt v√† s·ª± t·ªìn t·∫°i c·ªßa t·∫•t c·∫£ c√°c c·ªôt t·ª´ X_TRAIN_COLUMNS_ORDERED
        input_df_final_for_model = pd.DataFrame()  # Kh·ªüi t·∫°o df r·ªóng
        if processed_successfully:
            # Th√™m c√°c c·ªôt b·ªã thi·∫øu (n·∫øu c√≥ sau OHE) v·ªõi gi√° tr·ªã 0
            for col_model_expected in X_TRAIN_COLUMNS_ORDERED:
                if col_model_expected not in input_df_processed.columns:
                    input_df_processed[col_model_expected] = 0
            try:
                # Ch·ªçn v√† s·∫Øp x·∫øp l·∫°i c√°c c·ªôt theo ƒë√∫ng th·ª© t·ª± m√¥ h√¨nh mong ƒë·ª£i
                input_df_final_for_model = input_df_processed[X_TRAIN_COLUMNS_ORDERED]
                st.session_state.processed_input_df_display = input_df_final_for_model.copy()
            except KeyError as e:
                st.error(
                    f"L·ªói KeyError khi ch·ªçn c√°c c·ªôt cu·ªëi c√πng cho m√¥ h√¨nh: {e}. ƒêi·ªÅu n√†y th∆∞·ªùng x·∫£y ra n·∫øu X_TRAIN_COLUMNS_ORDERED ch·ª©a t√™n c·ªôt kh√¥ng c√≥ trong input_df_processed sau khi OHE. H√£y ki·ªÉm tra l·∫°i X_TRAIN_COLUMNS_ORDERED v√† qu√° tr√¨nh OHE.")
                processed_successfully = False
            except Exception as e:
                st.error(f"L·ªói kh√¥ng x√°c ƒë·ªãnh khi s·∫Øp x·∫øp l·∫°i c√°c c·ªôt cu·ªëi c√πng: {e}")
                processed_successfully = False

        # 4. Th·ª±c hi·ªán d·ª± ƒëo√°n (Effort l√† Person-Months t·ª´ m√¥ h√¨nh)
        ml_predictions_pm = {}
        if processed_successfully and not input_df_final_for_model.empty:
            for model_name, model_object in models.items():
                if model_object is not None:
                    try:
                        prediction_pm = model_object.predict(input_df_final_for_model)
                        ml_predictions_pm[model_name] = round(prediction_pm[0],
                                                              2)  # Gi·∫£ s·ª≠ m√¥ h√¨nh tr·∫£ v·ªÅ Person-Months
                    except Exception as e:
                        st.error(f"L·ªói khi d·ª± ƒëo√°n v·ªõi m√¥ h√¨nh {model_name}: {e}")
                        ml_predictions_pm[model_name] = "L·ªói d·ª± ƒëo√°n"
                else:
                    ml_predictions_pm[model_name] = "M√¥ h√¨nh ch∆∞a t·∫£i"
        else:
            st.warning("Kh√¥ng th·ªÉ th·ª±c hi·ªán d·ª± ƒëo√°n ML do l·ªói trong qu√° tr√¨nh chu·∫©n b·ªã d·ªØ li·ªáu.")
            for model_name_key in models.keys(): ml_predictions_pm[model_name_key] = "L·ªói d·ªØ li·ªáu"

        # Chuy·ªÉn ƒë·ªïi d·ª± ƒëo√°n ML t·ª´ Person-Months sang Person-Hours v√† l∆∞u v√†o session_state
        st.session_state.ml_predictions_ph = {
            name: (effort_pm * HOURS_PER_PERSON_MONTH if isinstance(effort_pm, (int, float)) else effort_pm)
            for name, effort_pm in ml_predictions_pm.items()
        }

        # 5. T√≠nh to√°n COCOMO II (Effort l√† Person-Months)
        kloc_for_cocomo = calculated_loc / 1000
        # √Ånh x·∫° project_type t·ª´ UI sang lo·∫°i COCOMO (v√≠ d·ª•)
        cocomo_project_type_map = {
            'Ph√°t tri·ªÉn m·ªõi': "Organic", 'N√¢ng c·∫•p l·ªõn': "Semi-detached",
            'B·∫£o tr√¨': "Organic", 'T√°i c·∫•u tr√∫c': "Semi-detached",
            'T√≠ch h·ª£p h·ªá th·ªëng': "Embedded", 'Kh√°c': "Organic"
        }
        cocomo_type_for_calc = cocomo_project_type_map.get(input_project_type, "Organic")  # S·ª≠ d·ª•ng input_project_type
        cocomo_effort_pm_estimated = estimate_cocomo_effort(kloc_for_cocomo, project_type_cocomo=cocomo_type_for_calc)
        # Chuy·ªÉn ƒë·ªïi COCOMO t·ª´ Person-Months sang Person-Hours v√† l∆∞u v√†o session_state
        st.session_state.cocomo_estimate_ph = round(cocomo_effort_pm_estimated * HOURS_PER_PERSON_MONTH, 0)

        st.success("ƒê√£ th·ª±c hi·ªán d·ª± ƒëo√°n Effort!")

# --- Khu v·ª±c ch√≠nh ---
main_area = st.container()
with main_area:
    st.header("üîç K·∫øt qu·∫£ ∆Ø·ªõc t√≠nh Chi ti·∫øt v√† Ph√¢n t√≠ch")

    if st.session_state.raw_input_df_display is not None:
        st.subheader("D·ªØ li·ªáu ƒë·∫ßu v√†o th√¥ (tr∆∞·ªõc khi x·ª≠ l√Ω cho ML):")
        st.dataframe(st.session_state.raw_input_df_display, use_container_width=True)

    if st.session_state.processed_input_df_display is not None:
        st.subheader("D·ªØ li·ªáu ƒë·∫ßu v√†o ƒë√£ x·ª≠ l√Ω (cho m√¥ h√¨nh ML):")
        st.dataframe(st.session_state.processed_input_df_display, use_container_width=True)
        st.caption(
            f"S·ªë c·ªôt mong ƒë·ª£i b·ªüi m√¥ h√¨nh: {len(X_TRAIN_COLUMNS_ORDERED)}. S·ªë c·ªôt th·ª±c t·∫ø truy·ªÅn v√†o: {st.session_state.processed_input_df_display.shape[1]}")

    if st.session_state.ml_predictions_ph:  # Ki·ªÉm tra session state m·ªõi
        st.subheader("üìä D·ª± ƒëo√°n Effort Ch√≠nh t·ª´ c√°c M√¥ h√¨nh ML (person-hours)")

        current_ml_predictions_ph = st.session_state.ml_predictions_ph

        model_names_ml = list(current_ml_predictions_ph.keys())
        num_models_ml = len(model_names_ml)

        cols_per_row = 3
        for i in range(0, num_models_ml, cols_per_row):
            row_cols = st.columns(cols_per_row)
            for j in range(cols_per_row):
                if i + j < num_models_ml:
                    model_name = model_names_ml[i + j]
                    effort_value_ph = current_ml_predictions_ph[model_name]
                    with row_cols[j]:
                        if isinstance(effort_value_ph, (int, float)):
                            st.metric(label=f"{model_name} (PH)", value=f"{effort_value_ph:,.0f}")
                        else:
                            st.metric(label=f"{model_name} (PH)", value=str(effort_value_ph))  # Hi·ªÉn th·ªã l·ªói n·∫øu c√≥
        st.markdown("---")

        # Bi·ªÉu ƒë·ªì So s√°nh T·ªïng h·ª£p
        st.subheader("üìà Bi·ªÉu ƒë·ªì So s√°nh Effort T·ªïng h·ª£p (person-hours)")
        comparison_data_for_chart = {}
        for model_name_chart, effort_ph_chart in current_ml_predictions_ph.items():
            if isinstance(effort_ph_chart, (int, float)):
                comparison_data_for_chart[model_name_chart] = effort_ph_chart

        if st.session_state.cocomo_estimate_ph is not None and isinstance(st.session_state.cocomo_estimate_ph,
                                                                          (int, float)):
            comparison_data_for_chart["COCOMO II"] = st.session_state.cocomo_estimate_ph

        if comparison_data_for_chart:
            df_comparison_chart = pd.DataFrame(list(comparison_data_for_chart.items()),
                                               columns=['Ph∆∞∆°ng ph√°p', 'Effort (Person-Hours)'])
            df_comparison_chart = df_comparison_chart.sort_values(by='Effort (Person-Hours)', ascending=False)

            fig, ax = plt.subplots(figsize=(10, 7))  # TƒÉng chi·ªÅu cao m·ªôt ch√∫t
            bars = ax.bar(df_comparison_chart['Ph∆∞∆°ng ph√°p'], df_comparison_chart['Effort (Person-Hours)'],
                          color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b'])  # M√†u s·∫Øc kh√°c nhau

            for bar in bars:
                yval = bar.get_height()
                plt.text(bar.get_x() + bar.get_width() / 2.0,
                         yval + 0.02 * max(df_comparison_chart['Effort (Person-Hours)']), f'{yval:,.0f}', ha='center',
                         va='bottom', fontsize=9)

            ax.set_ylabel('Effort ∆Ø·ªõc t√≠nh (Person-Hours)', fontsize=12)
            ax.set_title('So s√°nh Effort ∆Ø·ªõc t√≠nh gi·ªØa c√°c Ph∆∞∆°ng ph√°p', fontsize=14)
            plt.xticks(rotation=45, ha="right", fontsize=10)
            plt.yticks(fontsize=10)
            ax.grid(axis='y', linestyle='--', alpha=0.7)  # Th√™m l∆∞·ªõi ngang m·ªù
            plt.tight_layout()
            st.pyplot(fig)
        else:
            st.info("Kh√¥ng c√≥ ƒë·ªß d·ªØ li·ªáu h·ª£p l·ªá ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì so s√°nh t·ªïng h·ª£p.")

    # Hi·ªÉn th·ªã COCOMO metric ri√™ng l·∫ª
    if st.session_state.cocomo_estimate_ph is not None:
        st.subheader("‚öôÔ∏è ∆Ø·ªõc t√≠nh Effort t·ª´ COCOMO II (person-hours) - Chi ti·∫øt")
        st.metric(label="COCOMO II Effort (PH)", value=f"{st.session_state.cocomo_estimate_ph:,.0f}")

    if not st.session_state.ml_predictions_ph and st.session_state.cocomo_estimate_ph is None:
        st.info("Nh·∫≠p th√¥ng tin ·ªü thanh b√™n tr√°i v√† nh·∫•n 'üöÄ D·ª± ƒëo√°n Effort Ch√≠nh (ML & COCOMO II)' ƒë·ªÉ xem k·∫øt qu·∫£.")

    st.markdown("---")
    st.subheader("üìù Ch·ªâ s·ªë ƒê√°nh gi√° M√¥ h√¨nh (T√πy ch·ªçn)")
    st.info(
        "ƒê·ªÉ hi·ªÉn th·ªã c√°c ch·ªâ s·ªë ƒë√°nh gi√° (v√≠ d·ª•: MAE, RMSE, R¬≤) c·ªßa c√°c m√¥ h√¨nh, "
        "b·∫°n c·∫ßn t·∫£i ch√∫ng t·ª´ qu√° tr√¨nh hu·∫•n luy·ªán m√¥ h√¨nh v√† hi·ªÉn th·ªã t·∫°i ƒë√¢y."
    )

    st.markdown("---")
    st.subheader("H∆∞·ªõng d·∫´n Ti·∫øp theo v√† L∆∞u √Ω Quan Tr·ªçng")
    st.markdown("""
    1.  **CUNG C·∫§P FILE M√î H√åNH V√Ä PREPROCESSORS:** B·ªè comment c√°c d√≤ng `joblib.load(...)` trong h√†m `load_model_and_preprocessors()` v√† cung c·∫•p ƒë∆∞·ªùng d·∫´n ch√≠nh x√°c ƒë·∫øn c√°c file `.pkl` c·ªßa b·∫°n (scaler, encoders, models).
    2.  **X√ÅC ƒê·ªäNH `X_TRAIN_COLUMNS_ORDERED` CH√çNH X√ÅC:** ƒê√¢y l√† b∆∞·ªõc **C·ª∞C K·ª≤ QUAN TR·ªåNG**. Danh s√°ch n√†y ph·∫£i kh·ªõp ho√†n to√†n v·ªõi t√™n v√† th·ª© t·ª± c√°c c·ªôt c·ªßa d·ªØ li·ªáu b·∫°n ƒë√£ d√πng ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh (sau khi ƒë√£ one-hot encoding v√† scaling). H√£y ki·ªÉm tra v√† c·∫≠p nh·∫≠t c·∫©n th·∫≠n d·ª±a tr√™n output c·ªßa `encoder.get_feature_names_out()` ho·∫∑c `X_train.columns` c·ªßa b·∫°n.
    3.  **KI·ªÇM TRA LOGIC ONE-HOT ENCODING (OHE):** C√°ch b·∫°n l∆∞u v√† t·∫£i encoders (t·ª´ng c√°i m·ªôt hay d√πng `ColumnTransformer`) ph·∫£i nh·∫•t qu√°n. Logic OHE trong code c·∫ßn ph·∫£n √°nh ƒëi·ªÅu ƒë√≥.
    4.  **ƒê∆†N V·ªä EFFORT:** ƒê·∫£m b·∫£o r·∫±ng m√¥ h√¨nh ML c·ªßa b·∫°n ƒë∆∞·ª£c hu·∫•n luy·ªán ƒë·ªÉ d·ª± ƒëo√°n effort theo ƒë∆°n v·ªã **Person-Months**. Code hi·ªán t·∫°i gi·∫£ ƒë·ªãnh ƒëi·ªÅu n√†y v√† sau ƒë√≥ chuy·ªÉn ƒë·ªïi sang Person-Hours ƒë·ªÉ hi·ªÉn th·ªã. N·∫øu m√¥ h√¨nh c·ªßa b·∫°n d·ª± ƒëo√°n tr·ª±c ti·∫øp Person-Hours, b·∫°n c·∫ßn ƒëi·ªÅu ch·ªânh logic chuy·ªÉn ƒë·ªïi.
    5.  **C√ÅC L·ª∞A CH·ªåN CHO SELECTBOX:** C·∫≠p nh·∫≠t c√°c bi·∫øn `..._OPTIONS` (v√≠ d·ª•: `PROJECT_TYPES_OPTIONS`) v·ªõi c√°c gi√° tr·ªã th·ª±c t·∫ø t·ª´ d·ªØ li·ªáu c·ªßa b·∫°n ƒë·ªÉ c√°c dropdown menu hi·ªÉn th·ªã ƒë√∫ng.
    """)

# ƒê·ªÉ ch·∫°y ·ª©ng d·ª•ng n√†y:
# 1. C√†i ƒë·∫∑t: streamlit, pandas, numpy, scikit-learn, joblib, matplotlib, (xgboost n·∫øu d√πng)
# 2. L∆∞u file: app_ml_real_cols.py (ho·∫∑c t√™n kh√°c)
# 3. Chu·∫©n b·ªã c√°c file .pkl (m√¥ h√¨nh, scaler, encoders) v√† c·∫≠p nh·∫≠t ƒë∆∞·ªùng d·∫´n trong code.
# 4. C·∫¨P NH·∫¨T `X_TRAIN_COLUMNS_ORDERED` V√Ä C√ÅC `..._OPTIONS` CHO CH√çNH X√ÅC.
# 5. Ch·∫°y l·ªánh: streamlit run app_ml_real_cols.py
