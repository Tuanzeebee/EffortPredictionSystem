# -*- coding: utf-8 -*-
"""
app.py: ·ª®ng d·ª•ng Web Streamlit ƒë·ªÉ d·ª± ƒëo√°n Effort
(Bao g·ªìm M√¥ h√¨nh ML, COCOMO II Basic, FP, UCP v√† So s√°nh).
T√≠ch h·ª£p chuy·ªÉn ƒë·ªïi LOC/FP/UCP v√† t√≠nh to√°n Th·ªùi gian/Quy m√¥ d·ª± √°n.
"""

import streamlit as st
import pandas as pd
import numpy as np
import joblib
import os
from collections import OrderedDict
import math # C·∫ßn cho COCOMO
import traceback # Th√™m ƒë·ªÉ in l·ªói chi ti·∫øt

# Import c√°c l·ªõp c·∫ßn thi·∫øt
try:
    from sklearn.compose import ColumnTransformer
    from sklearn.pipeline import Pipeline
    from sklearn.impute import SimpleImputer
    from sklearn.preprocessing import RobustScaler, OneHotEncoder # Ho·∫∑c StandardScaler
    from sklearn.linear_model import LinearRegression
    from sklearn.tree import DecisionTreeRegressor
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.neural_network import MLPRegressor
    import xgboost as xgb
except ImportError as e:
    st.error(f"L·ªói Import th∆∞ vi·ªán: {e}. H√£y ƒë·∫£m b·∫£o c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt (streamlit, pandas, scikit-learn, joblib, xgboost) ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t trong m√¥i tr∆∞·ªùng c·ªßa b·∫°n.")
    st.stop()


# --- C·∫•u h√¨nh Trang v√† T·∫£i Artifacts ---

st.set_page_config(page_title="So s√°nh ∆Ø·ªõc t√≠nh Effort Ph·∫ßn m·ªÅm", layout="wide")

st.title("·ª®ng d·ª•ng So s√°nh ∆Ø·ªõc t√≠nh Effort, Th·ªùi gian & Quy m√¥ D·ª± √°n üìä")
st.write("""
Nh·∫≠p th√¥ng tin d·ª± √°n ho·∫∑c m·ªôt ch·ªâ s·ªë k√≠ch th∆∞·ªõc ch√≠nh (LOC, FP, UCP) ƒë·ªÉ nh·∫≠n ∆∞·ªõc t√≠nh effort,
th·ªùi gian ph√°t tri·ªÉn, quy m√¥ ƒë·ªôi ng≈© t·ª´ nhi·ªÅu m√¥ h√¨nh Machine Learning
v√† c√°c ph∆∞∆°ng ph√°p truy·ªÅn th·ªëng.
""")

# ƒê·ªãnh nghƒ©a ƒë∆∞·ªùng d·∫´n
OUTPUT_DIR = "."
PREPROCESSOR_PATH = os.path.join(OUTPUT_DIR, "preprocessor.joblib")
FEATURES_PATH = os.path.join(OUTPUT_DIR, "feature_names.joblib")
MODEL_PATHS = OrderedDict([
    ('Linear Regression', os.path.join(OUTPUT_DIR, "linear_regression_model.joblib")),
    ('Decision Tree', os.path.join(OUTPUT_DIR, "decision_tree_model.joblib")),
    ('Random Forest', os.path.join(OUTPUT_DIR, "random_forest_model.joblib")),
    ('XGBoost', os.path.join(OUTPUT_DIR, "xgboost_model.joblib")),
    ('MLP Regressor', os.path.join(OUTPUT_DIR, "mlp_regressor_model.joblib"))
])

@st.cache_resource
def load_all_artifacts(preprocessor_path, features_path, model_paths_dict):
    loaded_models = OrderedDict()
    preprocessor = None
    feature_names = None
    categorical_features_options = {}
    original_cols_order = []
    # all_loaded_successfully = True # Kh√¥ng c·∫ßn n·ªØa, s·∫Ω ki·ªÉm tra t·ª´ng ph·∫ßn

    if not os.path.exists(preprocessor_path):
        st.error(f"L·ªñI: Kh√¥ng t√¨m th·∫•y file preprocessor t·∫°i '{preprocessor_path}'")
        # return None, None, None, None, None # Gi·ªØ l·∫°i ƒë·ªÉ c√≥ th·ªÉ ch·∫°y m√¥ h√¨nh truy·ªÅn th·ªëng
    else:
        try:
            preprocessor = joblib.load(preprocessor_path)
            print("T·∫£i preprocessor th√†nh c√¥ng.")
            try:
                num_transformer_tuple = next(t for t in preprocessor.transformers_ if t[0] == 'num')
                cat_transformer_tuple = next(t for t in preprocessor.transformers_ if t[0] == 'cat')
                original_num_features = list(num_transformer_tuple[2])
                original_cat_features = list(cat_transformer_tuple[2])
                original_cols_order = original_num_features + original_cat_features
                print("Th·ª© t·ª± c·ªôt g·ªëc mong ƒë·ª£i:", original_cols_order)

                cat_pipeline = preprocessor.named_transformers_['cat']
                onehot_encoder = cat_pipeline.named_steps['onehot']

                if hasattr(onehot_encoder, 'categories_'):
                    if len(onehot_encoder.categories_) == len(original_cat_features):
                        for i, feature_name in enumerate(original_cat_features):
                            categories = onehot_encoder.categories_[i]
                            categorical_features_options[feature_name] = categories.tolist()
                        print("Tr√≠ch xu·∫•t danh m·ª•c t·ª´ OneHotEncoder th√†nh c√¥ng.")
                    else:
                        st.error(f"L·ªói: S·ªë l∆∞·ª£ng danh m·ª•c ({len(onehot_encoder.categories_)}) kh√¥ng kh·ªõp s·ªë c·ªôt ph√¢n lo·∫°i ({len(original_cat_features)}).")
                        preprocessor = None # V√¥ hi·ªáu h√≥a ML n·∫øu c√≥ l·ªói n√†y
                else:
                    st.error("L·ªói: Kh√¥ng t√¨m th·∫•y thu·ªôc t√≠nh 'categories_' trong OneHotEncoder.")
                    preprocessor = None # V√¥ hi·ªáu h√≥a ML
            except Exception as e_extract:
                st.error(f"L·ªói khi tr√≠ch xu·∫•t th√¥ng tin t·ª´ preprocessor: {e_extract}")
                preprocessor = None # V√¥ hi·ªáu h√≥a ML
        except Exception as e_load_prep:
            st.error(f"L·ªói nghi√™m tr·ªçng khi t·∫£i preprocessor: {e_load_prep}")
            preprocessor = None # ƒê·∫£m b·∫£o preprocessor l√† None n·∫øu l·ªói


    if not os.path.exists(features_path) and preprocessor: # Ch·ªâ c·∫ßn features_path n·∫øu c√≥ preprocessor
        st.error(f"L·ªñI: Kh√¥ng t√¨m th·∫•y file t√™n ƒë·∫∑c tr∆∞ng t·∫°i '{features_path}' (c·∫ßn cho preprocessor ƒë√£ t·∫£i).")
        preprocessor = None # V√¥ hi·ªáu h√≥a ML n·∫øu thi·∫øu features
    elif preprocessor: # Ch·ªâ t·∫£i features_path n·∫øu preprocessor ƒë∆∞·ª£c t·∫£i
        try:
            feature_names = joblib.load(features_path)
            print("T·∫£i feature names (ƒë√£ x·ª≠ l√Ω) th√†nh c√¥ng.")
            if isinstance(feature_names, np.ndarray): feature_names = feature_names.tolist()
            if not isinstance(feature_names, list):
                st.warning(f"ƒê·ªãnh d·∫°ng feature_names kh√¥ng ph·∫£i list (ki·ªÉu: {type(feature_names)}).")
                try: feature_names = list(feature_names)
                except TypeError:
                    st.error("Kh√¥ng th·ªÉ chuy·ªÉn ƒë·ªïi feature_names th√†nh list.")
                    preprocessor = None # V√¥ hi·ªáu h√≥a ML
        except Exception as e_load_feat:
            st.error(f"L·ªói khi t·∫£i feature names: {e_load_feat}")
            preprocessor = None # V√¥ hi·ªáu h√≥a ML


    models_actually_loaded = 0
    for name, path in model_paths_dict.items():
        if not os.path.exists(path):
            st.warning(f"C·∫£nh b√°o: Kh√¥ng t√¨m th·∫•y file m√¥ h√¨nh '{name}' t·∫°i '{path}'. B·ªè qua.")
            continue
        try:
            model = joblib.load(path)
            loaded_models[name] = model
            models_actually_loaded += 1
            print(f"T·∫£i m√¥ h√¨nh ML {name} th√†nh c√¥ng.")
        except Exception as e_load_model:
            st.warning(f"L·ªói khi t·∫£i m√¥ h√¨nh {name}: {e_load_model}. B·ªè qua.")

    if models_actually_loaded == 0 and preprocessor: # Ch·ªâ b√°o l·ªói n·∫øu preprocessor mong mu·ªën c√≥ model
         st.error("L·ªñI: Kh√¥ng t·∫£i ƒë∆∞·ª£c b·∫•t k·ª≥ m√¥ h√¨nh Machine Learning n√†o (nh∆∞ng preprocessor ƒë√£ ƒë∆∞·ª£c t·∫£i).")
         # loaded_models = OrderedDict() # Kh√¥ng c·∫ßn thi·∫øt ph·∫£i x√≥a, c√≥ th·ªÉ ƒë·ªÉ tr·ªëng

    # N·∫øu preprocessor kh√¥ng t·∫£i ƒë∆∞·ª£c, c√°c th√¥ng tin li√™n quan ƒë·∫øn ML c≈©ng kh√¥ng d√πng ƒë∆∞·ª£c
    if not preprocessor:
        feature_names = None
        original_cols_order = []
        categorical_features_options = {}
        # loaded_models = OrderedDict() # Kh√¥ng nh·∫•t thi·∫øt ph·∫£i x√≥a models n·∫øu preprocessor l·ªói, ch·ªâ l√† kh√¥ng d√πng ƒë∆∞·ª£c

    return preprocessor, feature_names, loaded_models, original_cols_order, categorical_features_options


preprocessor, feature_names_out, ml_models, original_cols_order, categorical_features_options = load_all_artifacts(
    PREPROCESSOR_PATH, FEATURES_PATH, MODEL_PATHS
)

# --- H√†m t√≠nh to√°n cho m√¥ h√¨nh truy·ªÅn th·ªëng v√† chuy·ªÉn ƒë·ªïi ---

def calculate_cocomo_basic(loc, mode, eaf, hrs_per_month_param):
    if not isinstance(loc, (int, float)) or loc <= 0: return "L·ªói (LOC <= 0 ho·∫∑c kh√¥ng h·ª£p l·ªá)", None
    if hrs_per_month_param <= 0: return "L·ªói (Gi·ªù/Th√°ng <= 0)", None
    kloc = loc / 1000.0
    params = {"Organic": {"a": 2.4, "b": 1.05, "c": 2.5, "d": 0.38},
              "Semi-detached": {"a": 3.0, "b": 1.12, "c": 2.5, "d": 0.35},
              "Embedded": {"a": 3.6, "b": 1.20, "c": 2.5, "d": 0.32}}
    if mode not in params: return "L·ªói (Ch·∫ø ƒë·ªô kh√¥ng h·ª£p l·ªá)", None
    a, b = params[mode]["a"], params[mode]["b"]
    try:
        person_months = a * (kloc ** b) * eaf
        person_hours = person_months * hrs_per_month_param
        return max(0.0, round(person_hours, 2)), max(0.0, round(person_months, 2))
    except Exception as e: return f"L·ªói t√≠nh to√°n COCOMO: {e}", None

def calculate_fp_effort(fp, hrs_per_fp_param):
    if not isinstance(fp, (int, float)) or fp <= 0: return "L·ªói (FP <= 0 ho·∫∑c kh√¥ng h·ª£p l·ªá)"
    if hrs_per_fp_param <= 0: return "L·ªói (Gi·ªù/FP <= 0)"
    try:
        person_hours = fp * hrs_per_fp_param
        return max(0.0, round(person_hours, 2))
    except Exception as e: return f"L·ªói t√≠nh to√°n FP: {e}"

def calculate_ucp_effort(ucp, hrs_per_ucp_param):
    if not isinstance(ucp, (int, float)) or ucp <= 0: return "L·ªói (UCP <= 0 ho·∫∑c kh√¥ng h·ª£p l·ªá)"
    if hrs_per_ucp_param <= 0: return "L·ªói (Gi·ªù/UCP <= 0)"
    try:
        person_hours = ucp * hrs_per_ucp_param
        return max(0.0, round(person_hours, 2))
    except Exception as e: return f"L·ªói t√≠nh to√°n UCP: {e}"

# --- H√†m chuy·ªÉn ƒë·ªïi ---
def convert_loc_to_fp(loc_val, loc_per_fp_ratio):
    if loc_per_fp_ratio <= 0: return "L·ªói (LOC/FP ratio <=0)"
    return round(loc_val / loc_per_fp_ratio, 2) if isinstance(loc_val, (int,float)) and loc_val > 0 else 0

def convert_fp_to_loc(fp_val, loc_per_fp_ratio):
    if loc_per_fp_ratio <= 0: return "L·ªói (LOC/FP ratio <=0)"
    return round(fp_val * loc_per_fp_ratio, 0) if isinstance(fp_val, (int,float)) and fp_val > 0 else 0

def convert_ucp_to_fp(ucp_val, ucp_fp_factor_val):
    if ucp_fp_factor_val <= 0: return "L·ªói (UCP to FP factor <=0)"
    return round(ucp_val * ucp_fp_factor_val, 2) if isinstance(ucp_val, (int,float)) and ucp_val > 0 else 0

def convert_fp_to_ucp(fp_val, ucp_fp_factor_val):
    if ucp_fp_factor_val <= 0: return "L·ªói (UCP to FP factor <=0)"
    return round(fp_val / ucp_fp_factor_val, 2) if isinstance(fp_val, (int,float)) and fp_val > 0 else 0


# --- H√†m t√≠nh Th·ªùi gian Ph√°t tri·ªÉn v√† Quy m√¥ ƒê·ªôi ng≈© ---
def calculate_development_time(effort_person_months, team_size_val, scheduling_factor=1.0):
    if not isinstance(effort_person_months, (int,float)) or effort_person_months <= 0 or team_size_val <= 0 : return "N/A"
    try:
        return round((effort_person_months / team_size_val) * scheduling_factor, 2)
    except: return "L·ªói"

def calculate_team_size(effort_person_months, dev_time_months_val, scheduling_factor=1.0):
    if not isinstance(effort_person_months, (int,float)) or effort_person_months <= 0 or dev_time_months_val <= 0: return "N/A"
    try:
        return round((effort_person_months / dev_time_months_val) * scheduling_factor, 2)
    except: return "L·ªói"

def calculate_cocomo_tdev(effort_person_months, mode):
    if not isinstance(effort_person_months, (int,float)) or effort_person_months <=0: return "N/A"
    params = {"Organic": {"c": 2.5, "d": 0.38},
              "Semi-detached": {"c": 2.5, "d": 0.35},
              "Embedded": {"c": 2.5, "d": 0.32}}
    if mode not in params: return "L·ªói mode"
    c, d = params[mode]["c"], params[mode]["d"]
    try:
        return round(c * (effort_person_months ** d), 2)
    except: return "L·ªói t√≠nh TDEV"


# --- Giao di·ªán Nh·∫≠p li·ªáu ---
st.sidebar.header("üìù Nh·∫≠p Th√¥ng tin D·ª± √°n")
input_values_sidebar = {} # ƒê·ªïi t√™n ƒë·ªÉ tr√°nh nh·∫ßm l·∫´n v·ªõi input_values ·ªü global scope n·∫øu c√≥

# 1. Ch·ªçn metric ch√≠nh v√† nh·∫≠p gi√° tr·ªã
st.sidebar.subheader("1. Ch·ªâ s·ªë K√≠ch th∆∞·ªõc Ch√≠nh & Chuy·ªÉn ƒë·ªïi")
primary_metric_type = st.sidebar.selectbox(
    "Ch·ªçn ch·ªâ s·ªë k√≠ch th∆∞·ªõc b·∫°n mu·ªën nh·∫≠p:",
    ("LOC", "Function Points (FP)", "Use Case Points (UCP)"),
    key="primary_metric_type"
)

available_languages = {
    "Assembly": 320, "C": 128, "COBOL": 100, "Fortran": 100,
    "Pascal": 90, "Ada": 70, "C++": 55, "Java": 53, "C#": 54, "JavaScript": 47,
    "Python": 30, "Perl": 25, "SQL": 12, "HTML": 40,
    "PowerBuilder": 15, "Visual Basic": 35, "Kh√°c (T√πy ch·ªânh)": 50
}
selected_language = st.sidebar.selectbox(
    "Ng√¥n ng·ªØ l·∫≠p tr√¨nh ch√≠nh (·∫£nh h∆∞·ªüng LOC/FP):",
    list(available_languages.keys()),
    index=list(available_languages.keys()).index("Java"),
    key="language_select"
)

if selected_language == "Kh√°c (T√πy ch·ªânh)":
    loc_per_fp_ratio = st.sidebar.number_input("T·ª∑ l·ªá LOC / FP t√πy ch·ªânh:", min_value=1, value=50, step=1, key="custom_loc_fp_ratio")
else:
    loc_per_fp_ratio = available_languages[selected_language]
    st.sidebar.caption(f"T·ª∑ l·ªá LOC/FP cho {selected_language}: {loc_per_fp_ratio}")
input_values_sidebar['loc_per_fp_ratio_used'] = loc_per_fp_ratio

ucp_to_fp_factor = st.sidebar.number_input("H·ªá s·ªë UCP sang FP (v√≠ d·ª•: 1 UCP = X FP):", min_value=0.1, value=2.5, step=0.1, format="%.2f", key="ucp_fp_factor", help="Gi√° tr·ªã tham kh·∫£o: 1.5 - 3.5")

if primary_metric_type == "LOC":
    input_values_sidebar['LOC_primary'] = st.sidebar.number_input("Lines of Code (LOC)", min_value=0, value=10000, step=100, key="loc_primary_input")
elif primary_metric_type == "Function Points (FP)":
    input_values_sidebar['FP_primary'] = st.sidebar.number_input("Function Points (FP)", min_value=0.0, value=100.0, step=10.0, format="%.2f", key="fp_primary_input")
else: # UCP
    input_values_sidebar['UCP_primary'] = st.sidebar.number_input("Use Case Points (UCP)", min_value=0.0, value=100.0, step=10.0, format="%.2f", key="ucp_primary_input")

st.sidebar.subheader("2. Tham s·ªë M√¥ h√¨nh Truy·ªÅn th·ªëng")
cocomo_mode = st.sidebar.selectbox("Ch·∫ø ƒë·ªô D·ª± √°n", ["Organic", "Semi-detached", "Embedded"], key="cocomo_mode")
eaf = st.sidebar.number_input("H·ªá s·ªë ƒêi·ªÅu ch·ªânh N·ªó l·ª±c (EAF)", min_value=0.1, value=1.0, step=0.1, format="%.2f", key="eaf")
hours_per_month = st.sidebar.number_input("S·ªë gi·ªù l√†m vi·ªác/th√°ng (quy ƒë·ªïi)", min_value=1, value=152, step=8, key="hrs_month")
hours_per_fp = st.sidebar.number_input("S·ªë gi·ªù/Function Point (NƒÉng su·∫•t FP)", min_value=0.1, value=10.0, step=0.5, format="%.1f", key="hrs_fp")
hours_per_ucp = st.sidebar.number_input("S·ªë gi·ªù/Use Case Point (NƒÉng su·∫•t UCP)", min_value=0.1, value=20.0, step=1.0, format="%.1f", key="hrs_ucp")

# Store traditional model params in input_values_sidebar
input_values_sidebar['cocomo_mode'] = cocomo_mode
input_values_sidebar['eaf'] = eaf
input_values_sidebar['hours_per_month'] = hours_per_month
input_values_sidebar['hours_per_fp'] = hours_per_fp
input_values_sidebar['hours_per_ucp'] = hours_per_ucp


if preprocessor and original_cols_order:
    st.sidebar.subheader("3. ƒê·∫∑c tr∆∞ng B·ªï sung (cho ML)")
    ml_specific_inputs = {}
    col_ml1, col_ml2 = st.sidebar.columns(2)
    ml_numeric_cols = [col for col in original_cols_order if col not in ['LOC', 'FP', 'UCP'] and (col not in categorical_features_options)]
    ml_categorical_cols = [col for col in original_cols_order if col in categorical_features_options and col not in ['LOC', 'FP', 'UCP']]

    with col_ml1:
        for i, col_name in enumerate(ml_numeric_cols):
            if i < (len(ml_numeric_cols) + 1) / 2 :
                 default_val = 0.0
                 if "Time" in col_name or "Month" in col_name : default_val = 6.0
                 elif "Size" in col_name or "Team" in col_name: default_val = 5.0
                 ml_specific_inputs[col_name] = st.number_input(f"{col_name}", value=default_val, step=1.0, format="%.1f", key=f"ml_num_{col_name}")
    with col_ml2:
        for i, col_name in enumerate(ml_numeric_cols):
            if i >= (len(ml_numeric_cols) + 1) / 2 :
                 default_val = 0.0
                 if "Time" in col_name or "Month" in col_name : default_val = 6.0
                 elif "Size" in col_name or "Team" in col_name: default_val = 5.0
                 ml_specific_inputs[col_name] = st.number_input(f"{col_name}", value=default_val, step=1.0, format="%.1f", key=f"ml_num_{col_name}")

    if ml_categorical_cols:
        st.sidebar.markdown("**Th√¥ng tin Ph√¢n lo·∫°i (cho ML)**")
        col_cat1_ml, col_cat2_ml = st.sidebar.columns(2) # ƒê·ªïi t√™n bi·∫øn ƒë·ªÉ tr√°nh tr√πng l·∫∑p
        with col_cat1_ml:
            for i, col_name in enumerate(ml_categorical_cols):
                if col_name in categorical_features_options:
                    if i < (len(ml_categorical_cols) +1) / 2:
                        options = categorical_features_options[col_name]
                        ml_specific_inputs[col_name] = st.selectbox(f"{col_name}", options=options, index=0, key=f"ml_cat_{col_name}_1")
        with col_cat2_ml:
            for i, col_name in enumerate(ml_categorical_cols):
                if col_name in categorical_features_options:
                    if i >= (len(ml_categorical_cols) + 1) / 2:
                        options = categorical_features_options[col_name]
                        ml_specific_inputs[col_name] = st.selectbox(f"{col_name}", options=options, index=0, key=f"ml_cat_{col_name}_2")
    input_values_sidebar.update(ml_specific_inputs)
else:
    st.sidebar.info("Ph·∫ßn nh·∫≠p li·ªáu cho ML b·ªã v√¥ hi·ªáu h√≥a do preprocessor ho·∫∑c th√¥ng tin c·ªôt kh√¥ng ƒë∆∞·ª£c t·∫£i.")

st.sidebar.subheader("4. Tham s·ªë Th·ªùi gian & Quy m√¥")
desired_team_size = st.sidebar.number_input("Quy m√¥ ƒë·ªôi ng≈© mong mu·ªën (s·ªë ng∆∞·ªùi)", min_value=0.1, value=5.0, step=0.5, format="%.1f", key="desired_team_size")
desired_dev_time = st.sidebar.number_input("Th·ªùi gian ph√°t tri·ªÉn mong mu·ªën (th√°ng)", min_value=0.1, value=6.0, step=0.5, format="%.1f", key="desired_dev_time")
input_values_sidebar['desired_team_size'] = desired_team_size
input_values_sidebar['desired_dev_time'] = desired_dev_time

calculate_button = st.sidebar.button("üìä ∆Ø·ªõc t√≠nh & So s√°nh", use_container_width=True, type="primary")

# --- X·ª≠ l√Ω v√† Hi·ªÉn th·ªã K·∫øt qu·∫£ ---
if calculate_button:
    st.divider()
    st.subheader("üìä K·∫øt qu·∫£ ∆Ø·ªõc t√≠nh T·ªïng h·ª£p")

    actual_loc = None
    actual_fp = None
    actual_ucp = None
    conversion_details = []

    current_loc_per_fp = input_values_sidebar['loc_per_fp_ratio_used']
    current_ucp_to_fp_factor = ucp_to_fp_factor # L·∫•y t·ª´ input tr·ª±c ti·∫øp

    st.markdown("#### 0. Gi√° tr·ªã K√≠ch th∆∞·ªõc ƒê·∫ßu v√†o & Chuy·ªÉn ƒë·ªïi")
    if primary_metric_type == "LOC":
        actual_loc = input_values_sidebar.get('LOC_primary')
        if isinstance(actual_loc, (int, float)) and actual_loc > 0:
            actual_fp = convert_loc_to_fp(actual_loc, current_loc_per_fp)
            if isinstance(actual_fp, str): # L·ªói t·ª´ convert
                conversion_details.append(f"LOC ({actual_loc}) sang FP: {actual_fp}")
                actual_ucp = "L·ªói (do FP)"
            elif isinstance(actual_fp, (int,float)) and actual_fp > 0:
                actual_ucp = convert_fp_to_ucp(actual_fp, current_ucp_to_fp_factor)
                if isinstance(actual_ucp, str): conversion_details.append(f"FP ({actual_fp}) sang UCP: {actual_ucp}")
            else: actual_ucp = 0 # Ho·∫∑c "Kh√¥ng t√≠nh (FP=0)"
        else:
            actual_loc = actual_loc if actual_loc is not None else "Ch∆∞a nh·∫≠p"
            actual_fp = "Kh√¥ng t√≠nh (LOC kh√¥ng h·ª£p l·ªá)"
            actual_ucp = "Kh√¥ng t√≠nh (LOC kh√¥ng h·ª£p l·ªá)"
        conversion_details.insert(0, f"**ƒê·∫ßu v√†o ch√≠nh: LOC = {actual_loc}**")

    elif primary_metric_type == "Function Points (FP)":
        actual_fp = input_values_sidebar.get('FP_primary')
        if isinstance(actual_fp, (int, float)) and actual_fp > 0:
            actual_loc = convert_fp_to_loc(actual_fp, current_loc_per_fp)
            actual_ucp = convert_fp_to_ucp(actual_fp, current_ucp_to_fp_factor)
            if isinstance(actual_loc, str): conversion_details.append(f"FP ({actual_fp}) sang LOC: {actual_loc}")
            if isinstance(actual_ucp, str): conversion_details.append(f"FP ({actual_fp}) sang UCP: {actual_ucp}")
        else:
            actual_fp = actual_fp if actual_fp is not None else "Ch∆∞a nh·∫≠p"
            actual_loc = "Kh√¥ng t√≠nh (FP kh√¥ng h·ª£p l·ªá)"
            actual_ucp = "Kh√¥ng t√≠nh (FP kh√¥ng h·ª£p l·ªá)"
        conversion_details.insert(0, f"**ƒê·∫ßu v√†o ch√≠nh: FP = {actual_fp}**")

    else: # UCP
        actual_ucp = input_values_sidebar.get('UCP_primary')
        if isinstance(actual_ucp, (int, float)) and actual_ucp > 0:
            actual_fp = convert_ucp_to_fp(actual_ucp, current_ucp_to_fp_factor)
            if isinstance(actual_fp, str): # L·ªói
                conversion_details.append(f"UCP ({actual_ucp}) sang FP: {actual_fp}")
                actual_loc = "L·ªói (do FP)"
            elif isinstance(actual_fp, (int,float)) and actual_fp > 0:
                actual_loc = convert_fp_to_loc(actual_fp, current_loc_per_fp)
                if isinstance(actual_loc, str): conversion_details.append(f"FP ({actual_fp}) sang LOC: {actual_loc}")
            else: actual_loc = 0 # Ho·∫∑c "Kh√¥ng t√≠nh (FP=0)"
        else:
            actual_ucp = actual_ucp if actual_ucp is not None else "Ch∆∞a nh·∫≠p"
            actual_fp = "Kh√¥ng t√≠nh (UCP kh√¥ng h·ª£p l·ªá)"
            actual_loc = "Kh√¥ng t√≠nh (UCP kh√¥ng h·ª£p l·ªá)"
        conversion_details.insert(0, f"**ƒê·∫ßu v√†o ch√≠nh: UCP = {actual_ucp}**")

    conversion_details.append(f"T·ª∑ l·ªá LOC/FP s·ª≠ d·ª•ng: {current_loc_per_fp} ({selected_language})")
    conversion_details.append(f"H·ªá s·ªë UCP/FP s·ª≠ d·ª•ng: {current_ucp_to_fp_factor}")

    col_conv1, col_conv2, col_conv3 = st.columns(3)
    with col_conv1: st.metric(label="Lines of Code (LOC)", value=f"{actual_loc:,.0f}" if isinstance(actual_loc, (int,float)) else str(actual_loc))
    with col_conv2: st.metric(label="Function Points (FP)", value=f"{actual_fp:,.2f}" if isinstance(actual_fp, (int,float)) else str(actual_fp))
    with col_conv3: st.metric(label="Use Case Points (UCP)", value=f"{actual_ucp:,.2f}" if isinstance(actual_ucp, (int,float)) else str(actual_ucp))
    for detail in conversion_details: st.caption(detail)

    all_results = OrderedDict()
    error_messages_ml = {}
    effort_person_months_map = {}

    if preprocessor and feature_names_out and ml_models and original_cols_order:
        st.markdown("#### 1. D·ª± ƒëo√°n Effort t·ª´ M√¥ h√¨nh Machine Learning")
        try:
            ml_feature_inputs_for_df = {}
            for col in original_cols_order:
                if col == 'LOC': ml_feature_inputs_for_df[col] = actual_loc if isinstance(actual_loc, (int,float)) else np.nan
                elif col == 'FP': ml_feature_inputs_for_df[col] = actual_fp if isinstance(actual_fp, (int,float)) else np.nan
                elif col == 'UCP': ml_feature_inputs_for_df[col] = actual_ucp if isinstance(actual_ucp, (int,float)) else np.nan
                elif col in input_values_sidebar: ml_feature_inputs_for_df[col] = input_values_sidebar[col]
                else: ml_feature_inputs_for_df[col] = np.nan

            input_df_ml = pd.DataFrame([ml_feature_inputs_for_df], columns=original_cols_order)
            # st.caption("D·ªØ li·ªáu ƒë·∫ßu v√†o cho ML (tr∆∞·ªõc pre-processing):"); st.dataframe(input_df_ml.astype(str))

            input_processed_np = preprocessor.transform(input_df_ml)
            if isinstance(feature_names_out, list) and len(feature_names_out) == input_processed_np.shape[1]:
                input_processed_df = pd.DataFrame(input_processed_np, columns=feature_names_out)
                for model_name, loaded_model in ml_models.items():
                    try:
                        pred = loaded_model.predict(input_processed_df)
                        pv = float(pred[0]) if pred.size > 0 else 0.0
                        all_results[f"ML: {model_name}"] = max(0.0, round(pv, 2))
                        if input_values_sidebar['hours_per_month'] > 0 and pv > 0:
                             effort_person_months_map[f"ML: {model_name}"] = round(pv / input_values_sidebar['hours_per_month'], 2)
                        else: effort_person_months_map[f"ML: {model_name}"] = "L·ªói (gi·ªù/th√°ng)"
                    except Exception as model_pred_e:
                        all_results[f"ML: {model_name}"] = "L·ªói"; error_messages_ml[model_name] = str(model_pred_e)
                        effort_person_months_map[f"ML: {model_name}"] = "L·ªói"
            else:
                st.error(f"L·ªói ML: Feature names ({len(feature_names_out)}) kh√¥ng kh·ªõp c·ªôt sau transform ({input_processed_np.shape[1]}).")
                for model_name in ml_models.keys(): all_results[f"ML: {model_name}"] = "L·ªói (Config)"; effort_person_months_map[f"ML: {model_name}"] = "L·ªói (Config)"
        except Exception as e_ml_process:
            st.error(f"L·ªói x·ª≠ l√Ω/d·ª± ƒëo√°n ML: {e_ml_process}")
            for model_name in ml_models.keys(): all_results[f"ML: {model_name}"] = "L·ªói (Process)"; effort_person_months_map[f"ML: {model_name}"] = "L·ªói (Process)"
    else: st.info("Ph·∫ßn ML kh√¥ng th·ª±c hi·ªán do thi·∫øu th√†nh ph·∫ßn.")

    st.markdown("#### 2. ∆Ø·ªõc t√≠nh Effort t·ª´ M√¥ h√¨nh Truy·ªÅn th·ªëng")
    traditional_captions_display = []
    hpm = input_values_sidebar['hours_per_month'] # Vi·∫øt t·∫Øt ƒë·ªÉ d·ªÖ ƒë·ªçc

    cocomo_effort_hours, cocomo_effort_months = "N/A", "N/A"
    if isinstance(actual_loc, (int, float)) and actual_loc > 0:
        cocomo_effort_hours, cocomo_effort_months = calculate_cocomo_basic(actual_loc, input_values_sidebar['cocomo_mode'], input_values_sidebar['eaf'], hpm)
    all_results['COCOMO II (Basic)'] = cocomo_effort_hours
    effort_person_months_map['COCOMO II (Basic)'] = cocomo_effort_months
    traditional_captions_display.append(f"* **COCOMO II:** LOC={actual_loc}, Mode={input_values_sidebar['cocomo_mode']}, EAF={input_values_sidebar['eaf']}, Hrs/M={hpm}")

    fp_effort_hours = "N/A"
    if isinstance(actual_fp, (int, float)) and actual_fp > 0:
        fp_effort_hours = calculate_fp_effort(actual_fp, input_values_sidebar['hours_per_fp'])
    all_results['Function Points'] = fp_effort_hours
    if isinstance(fp_effort_hours, (int,float)) and hpm > 0 : effort_person_months_map['Function Points'] = round(fp_effort_hours / hpm, 2)
    else: effort_person_months_map['Function Points'] = "L·ªói" if not isinstance(fp_effort_hours, (int,float)) else "L·ªói (hpm)"
    traditional_captions_display.append(f"* **FP:** FP={actual_fp}, Hrs/FP={input_values_sidebar['hours_per_fp']}")

    ucp_effort_hours = "N/A"
    if isinstance(actual_ucp, (int, float)) and actual_ucp > 0:
        ucp_effort_hours = calculate_ucp_effort(actual_ucp, input_values_sidebar['hours_per_ucp'])
    all_results['Use Case Points'] = ucp_effort_hours
    if isinstance(ucp_effort_hours, (int,float)) and hpm > 0: effort_person_months_map['Use Case Points'] = round(ucp_effort_hours / hpm, 2)
    else: effort_person_months_map['Use Case Points'] = "L·ªói" if not isinstance(ucp_effort_hours, (int,float)) else "L·ªói (hpm)"
    traditional_captions_display.append(f"* **UCP:** UCP={actual_ucp}, Hrs/UCP={input_values_sidebar['hours_per_ucp']}")
    st.markdown("**Tham s·ªë s·ª≠ d·ª•ng cho m√¥ h√¨nh truy·ªÅn th·ªëng:**"); [st.markdown(c) for c in traditional_captions_display]

    st.markdown("#### 3. B·∫£ng v√† Bi·ªÉu ƒë·ªì So s√°nh Effort")

    # S·ª≠a l·ªói PyArrow b·∫±ng c√°ch chuy·ªÉn ƒë·ªïi c·ªôt sang string tr∆∞·ªõc khi hi·ªÉn th·ªã
    def safe_format_display(x):
        if isinstance(x, (int, float)): return f"{x:,.2f}"
        return str(x) # ƒê·∫£m b·∫£o m·ªçi th·ª© l√† string

    if all_results:
        result_list_effort = [{'M√¥ H√¨nh ∆Ø·ªõc T√≠nh': name,
                               'Effort (person-hours)': val,
                               'Effort (person-months)': effort_person_months_map.get(name, "N/A")}
                              for name, val in all_results.items()]
        result_df_effort = pd.DataFrame(result_list_effort)

        # Chuy·ªÉn ƒë·ªïi c√°c c·ªôt sang string ƒë·ªÉ hi·ªÉn th·ªã an to√†n v·ªõi st.dataframe
        df_effort_display = result_df_effort.copy()
        df_effort_display['Effort (person-hours)'] = df_effort_display['Effort (person-hours)'].apply(safe_format_display)
        df_effort_display['Effort (person-months)'] = df_effort_display['Effort (person-months)'].apply(safe_format_display)

        st.write("B·∫£ng so s√°nh Effort:"); st.dataframe(df_effort_display, use_container_width=True, hide_index=True)

        st.write("Bi·ªÉu ƒë·ªì so s√°nh Effort (person-hours):")
        try:
            chart_df_effort = result_df_effort.copy() # D√πng DataFrame g·ªëc cho bi·ªÉu ƒë·ªì
            chart_df_effort['Effort (person-hours)'] = pd.to_numeric(chart_df_effort['Effort (person-hours)'], errors='coerce')
            chart_df_effort.dropna(subset=['Effort (person-hours)'], inplace=True)
            if not chart_df_effort.empty:
                st.bar_chart(chart_df_effort.set_index('M√¥ H√¨nh ∆Ø·ªõc T√≠nh')['Effort (person-hours)'])
            else: st.info("Kh√¥ng c√≥ d·ªØ li·ªáu effort h·ª£p l·ªá ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì.")
        except Exception as chart_e: st.warning(f"Kh√¥ng th·ªÉ v·∫Ω bi·ªÉu ƒë·ªì effort: {chart_e}")
    else: st.warning("Kh√¥ng c√≥ k·∫øt qu·∫£ effort n√†o.")

    st.markdown("#### 4. ∆Ø·ªõc t√≠nh Th·ªùi gian Ph√°t tri·ªÉn & Quy m√¥ ƒê·ªôi ng≈©")
    if effort_person_months_map:
        time_size_results_list = []
        has_valid_effort_pm = any(isinstance(val, (int, float)) and val > 0 for val in effort_person_months_map.values())
        if not has_valid_effort_pm: st.warning("Kh√¥ng c√≥ effort (person-months) h·ª£p l·ªá ƒë·ªÉ t√≠nh Th·ªùi gian/Quy m√¥.")
        else:
            for model_name, effort_pm_val in effort_person_months_map.items():
                cocomo_tdev_val, dev_time_calc, team_size_calc = "N/A", "N/A", "N/A"
                if isinstance(effort_pm_val, (int,float)) and effort_pm_val > 0:
                    if model_name == 'COCOMO II (Basic)':
                        cocomo_tdev_val = calculate_cocomo_tdev(effort_pm_val, input_values_sidebar['cocomo_mode'])
                    if input_values_sidebar['desired_team_size'] > 0:
                        dev_time_calc = calculate_development_time(effort_pm_val, input_values_sidebar['desired_team_size'])
                    if input_values_sidebar['desired_dev_time'] > 0:
                        team_size_calc = calculate_team_size(effort_pm_val, input_values_sidebar['desired_dev_time'])
                time_size_results_list.append({
                    'M√¥ H√¨nh Effort': model_name,
                    'Effort (person-months)': effort_pm_val,
                    'TDEV (th√°ng) - COCOMO': cocomo_tdev_val,
                    f'TDEV (th√°ng) v·ªõi Team={input_values_sidebar["desired_team_size"]}': dev_time_calc,
                    f'Team Size cho TDEV={input_values_sidebar["desired_dev_time"]} th√°ng': team_size_calc
                })
            if time_size_results_list:
                result_df_time_size = pd.DataFrame(time_size_results_list)
                # Chuy·ªÉn ƒë·ªïi t·∫•t c·∫£ c√°c c·ªôt sang string ƒë·ªÉ hi·ªÉn th·ªã an to√†n
                df_time_size_display = result_df_time_size.astype(str) # C√°ch ƒë∆°n gi·∫£n nh·∫•t
                # Ho·∫∑c d√πng safe_format_display cho t·ª´ng c·ªôt n·∫øu c·∫ßn ƒë·ªãnh d·∫°ng s·ªë c·ª• th·ªÉ
                # for col in df_time_size_display.columns:
                #    df_time_size_display[col] = df_time_size_display[col].apply(safe_format_display)

                st.write("B·∫£ng ∆∞·ªõc t√≠nh Th·ªùi gian & Quy m√¥:")
                st.dataframe(df_time_size_display, use_container_width=True, hide_index=True)
                st.caption(f"Gi·ªù/th√°ng quy ƒë·ªïi: {hpm}. COCOMO TDEV ch·ªâ √°p d·ª•ng cho COCOMO II. C√°c t√≠nh to√°n kh√°c gi·∫£ ƒë·ªãnh Effort = Team * Time.")
            else: st.info("Kh√¥ng c√≥ k·∫øt qu·∫£ Th·ªùi gian/Quy m√¥.")
    else: st.warning("Kh√¥ng c√≥ d·ªØ li·ªáu effort (person-months) ƒë·ªÉ t√≠nh Th·ªùi gian/Quy m√¥.")

    if error_messages_ml:
        st.subheader("‚ö†Ô∏è Chi ti·∫øt l·ªói d·ª± ƒëo√°n ML:"); [st.caption(f"**{name}:** {msg}") for name, msg in error_messages_ml.items()]
    st.info("""**L∆∞u √Ω quan tr·ªçng:** K·∫øt qu·∫£ ch·ªâ l√† **∆∞·ªõc t√≠nh**. ƒê·ªô ch√≠nh x√°c ph·ª• thu·ªôc v√†o d·ªØ li·ªáu v√† tham s·ªë. S·ª≠ d·ª•ng nh∆∞ m·ªôt ƒëi·ªÉm tham kh·∫£o.""")

elif not calculate_button:
    # Ch·ªâ hi·ªÉn th·ªã th√¥ng b√°o l·ªói t·∫£i artifact khi ch∆∞a nh·∫•n n√∫t v√† c√≥ v·∫•n ƒë·ªÅ
    if not preprocessor and (os.path.exists(PREPROCESSOR_PATH) or os.path.exists(FEATURES_PATH)):
         st.warning("Kh√¥ng th·ªÉ t·∫£i preprocessor ho·∫∑c feature names cho ML. Ch·ª©c nƒÉng ML c√≥ th·ªÉ b·ªã h·∫°n ch·∫ø.")
    if not ml_models and any(os.path.exists(p) for p in MODEL_PATHS.values()):
         st.warning("Kh√¥ng th·ªÉ t·∫£i m·ªôt ho·∫∑c nhi·ªÅu m√¥ h√¨nh ML. Ch·ª©c nƒÉng ML c√≥ th·ªÉ b·ªã h·∫°n ch·∫ø.")


st.markdown("---"); st.caption("·ª®ng d·ª•ng demo.")